{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc\n",
    "import os \n",
    "from time import time\n",
    "import sys\n",
    "from sklearn.model_selection import KFold, GroupKFold, train_test_split\n",
    "import json\n",
    "from numba import jit\n",
    "import re\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# import modules\n",
    "# sys.path.append('../utils/')\n",
    "# from large_file_pickle import pickle_dump, pickle_load\n",
    "# # from notifications import send_line_notification, notify_slack\n",
    "# from memory_optimize import memory_reducer\n",
    "# from util import *\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from typing import List, Optional, Union, Tuple, Dict\n",
    "# from encoders import frequency_encoding\n",
    "from contextlib import contextmanager\n",
    "\n",
    "sys.path.append('../py/')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_colwidth', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment to check reproducibility\n",
    "# comment to check reproducibility2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modules  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils\n",
    "\n",
    "### util function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def groupings(df, cols, agg_dict, pref='') -> object:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        object: \n",
    "    \"\"\"\n",
    "    group_df = df.groupby(cols).agg(agg_dict)\n",
    "    group_df.columns = [pref + c[0] + \"_\" + c[1] for c in list(group_df.columns)]\n",
    "    group_df.reset_index(inplace = True)\n",
    "    \n",
    "    return group_df\n",
    "\n",
    "@contextmanager\n",
    "def timer(name, logger=None):\n",
    "    \"\"\"時間計測\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    if logger:\n",
    "        logger.log(logging.DEBUG, f'[{name}] start')\n",
    "    else:\n",
    "        print(f'[{name}] start')\n",
    "    yield\n",
    "    if logger:\n",
    "        logger.log(logging.DEBUG, f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    else:\n",
    "        print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "def get_val_score(y_true, y_pred, obj=\"RMSE\"):\n",
    "    # RMSE\n",
    "    if obj == \"RMSE\":\n",
    "        val_score = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    elif obj == \"QWK\":\n",
    "        val_score = qwk(y_true, y_pred, max_rat=3)\n",
    "    else:\n",
    "        raise ValueError(\"valuation is not defined!\")\n",
    "    return val_score\n",
    "\n",
    "def memory_reducer(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        print(col)\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    \"\"\"関数の並列処理\n",
    "    \"\"\"\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count(), verbose=5)(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.callback import _format_eval_result\n",
    "\n",
    "def log_evaluation(logger, period=100, show_stdv=True, level=logging.DEBUG):\n",
    "    def _callback(env):\n",
    "        if period > 0 and env.evaluation_result_list and (env.iteration + 1) % period == 0:\n",
    "            result = '\\t'.join([_format_eval_result(x, show_stdv) for x in env.evaluation_result_list])\n",
    "            logger.log(level, '[{}]\\t{}'.format(env.iteration + 1, result))\n",
    "\n",
    "    _callback.order = 10\n",
    "    return _callback\n",
    "\n",
    "# ロガーの作成\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def log_output(subject):\n",
    "    logger = logging.getLogger('main')\n",
    "    for h in logger.handlers:\n",
    "        logger.removeHandler(h)\n",
    "\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    now = int(time.time())\n",
    "\n",
    "    log_dir = os.path.join(os.path.dirname(\"__file__\"), \"../logs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    log_path = Path(log_dir) / \"{}_{}.log\".format(subject, now)\n",
    "    fh = logging.FileHandler(log_path)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    return logger, log_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacOSFile(object):\n",
    "\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            # print(n, idx)\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            # print(batch_size)\n",
    "            # print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            # print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "        print(\"calculate done!\")\n",
    "\n",
    "\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def pickle_load(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(MacOSFile(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Features(metaclass=ABCMeta):\n",
    "\n",
    "    def __init__(self, params, logger=None):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.datatype = params[\"datatype\"]\n",
    "        self.debug = params[\"debug\"]\n",
    "        self.is_overwrite = params[\"is_overwrite\"]\n",
    "        self.org_columns = []\n",
    "        self.logger = logger\n",
    "\n",
    "        self.input_dir = os.path.join(os.path.dirname(\"__file__\"), \"../input\")\n",
    "        self.df_path = Path(self.input_dir) / f\"{self.datatype}.csv\"\n",
    "\n",
    "        self.save_dir = os.path.join(os.path.dirname(\"__file__\"), f\"../feature\")\n",
    "        self.save_type_dir = Path(self.save_dir) / f\"{self.datatype}\"\n",
    "        self.save_path = Path(self.save_type_dir) / f\"{self.name}.pkl\"\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        os.makedirs(self.save_type_dir, exist_ok=True)\n",
    "\n",
    "    def feature_extract(self, org_train, org_test):\n",
    "        if self.check_feature_exec():\n",
    "            with timer(f\"FE: {self.name}\", self.logger):\n",
    "                a = self.calc_feature(org_train, org_test)\n",
    "            return a\n",
    "\n",
    "    @abstractmethod\n",
    "    def calc_feature(self):\n",
    "        \"\"\"calc and save features\n",
    "        Return: feature_df\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def format_and_save_feats(self, feat_df):\n",
    "        \"\"\"保存するカラムなど特徴量の形式を指定する\n",
    "        \"\"\"\n",
    "        feat_cols = [c for c in list(feat_df.columns) if c not in self.org_columns]\n",
    "        pickle_dump(feat_df[feat_cols], self.save_path)\n",
    "\n",
    "        del feat_df\n",
    "        gc.collect()\n",
    "\n",
    "    def check_feature_exec(self):\n",
    "        \"\"\"\n",
    "        すでに対象の特徴が存在するかどうかをcheckする\n",
    "        Returns: bool (Falseなら特徴作成しない)\n",
    "\n",
    "        \"\"\"\n",
    "        path = self.save_path\n",
    "\n",
    "        if self.is_overwrite:\n",
    "            print(f\"overwrite features : {self.name}\")\n",
    "            return True\n",
    "        else:\n",
    "            if os.path.exists(path) is False:\n",
    "                print(f\"creates new file : {self.name}\")\n",
    "                return True\n",
    "\n",
    "        print(f\"file exists : {self.name}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LightGBM():\n",
    "    def __init__(self, param):\n",
    "\n",
    "        self.predict_type = param[\"predict_type\"] # classifier, regressor\n",
    "        self.train_params = param[\"train_params\"]\n",
    "        self.train_cols = param[\"train_cols\"]\n",
    "        self.cat_cols = param[\"cat_cols\"]\n",
    "        self.target = param[\"target\"]\n",
    "        self.is_debug = param[\"is_debug\"]\n",
    "\n",
    "    def train(self, train, valid, logger):\n",
    "        if type(train) != pd.DataFrame or type(valid) != pd.DataFrame:\n",
    "            raise ValueError('Parameter train and valid must be pandas.DataFrame')\n",
    "\n",
    "        if list(train.columns) != list(valid.columns):\n",
    "            raise ValueError('Train and valid must have a same column list')\n",
    "\n",
    "        trn_x, trn_y = train[self.train_cols], train[self.target]\n",
    "        val_x, val_y = valid[self.train_cols], valid[self.target]\n",
    "        callbacks = [log_evaluation(logger, period=500)]\n",
    "        \n",
    "        if self.predict_type == \"binary_classifier\":\n",
    "            clf = lgb.LGBMClassifier(**self.train_params)\n",
    "            clf.fit(\n",
    "                trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "                verbose=500,\n",
    "                early_stopping_rounds=500,\n",
    "                callbacks=callbacks,\n",
    "                categorical_feature = self.cat_cols,\n",
    "            )\n",
    "            oof = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            \n",
    "        elif self.predict_type == \"multi_classifier\":\n",
    "            clf = lgb.LGBMClassifier(**self.train_params)\n",
    "            clf.fit(\n",
    "                trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "                verbose=500,\n",
    "                early_stopping_rounds=500,\n",
    "                callbacks=callbacks,\n",
    "                categorical_feature = self.cat_cols,\n",
    "                eval_metric=eval_qwk_lgb\n",
    "            )\n",
    "            oof = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "\n",
    "        elif self.predict_type == \"regressor\":\n",
    "            clf = lgb.LGBMRegressor(**self.train_params)\n",
    "            clf.fit(\n",
    "                trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "                verbose=500,\n",
    "                early_stopping_rounds=500,\n",
    "                callbacks=callbacks,\n",
    "                categorical_feature=self.cat_cols,\n",
    "            )\n",
    "\n",
    "            oof = clf.predict(val_x, num_iteration=clf.best_iteration_)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"unknown prediction type !!\")\n",
    "\n",
    "        self.clf = clf\n",
    "\n",
    "        # feature importance\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        feature_importance_df[\"feature\"] = self.train_cols\n",
    "        feature_importance_df[\"importance\"] = self.clf.feature_importances_\n",
    "\n",
    "        return clf, oof, feature_importance_df\n",
    "\n",
    "    def predict(self, test, logger):\n",
    "        if self.predict_type == \"classifier\":\n",
    "            prediction = self.clf.predict_proba(test[self.train_cols],\n",
    "                                                num_iteration=self.clf.best_iteration_)[:, 1]\n",
    "        elif self.predict_type == \"multi_classifier\":\n",
    "            prediction = self.clf.predict_proba(test[self.train_cols],\n",
    "                                                num_iteration=self.clf.best_iteration_)\n",
    "        elif self.predict_type == \"regressor\":\n",
    "            prediction = self.clf.predict(test[self.train_cols],\n",
    "                                          num_iteration=self.clf.best_iteration_)\n",
    "        else:\n",
    "            raise ValueError(\"unknown prediction type !!\")\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def save_model(self, save_dir):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def qwk(y_true, y_pred, max_rat= 3):\n",
    "    y_true_ = np.asarray(y_true, dtype=int)\n",
    "    y_pred_ = np.asarray(y_pred, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    numerator = 0\n",
    "    for k in range(y_true_.shape[0]):\n",
    "        i, j = y_true_[k], y_pred_[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        numerator += (i - j) * (i - j)\n",
    "\n",
    "    denominator = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            denominator += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    denominator /= y_true_.shape[0]\n",
    "    return 1 - numerator / denominator\n",
    "\n",
    "def eval_qwk_lgb(y_true: Union[np.ndarray, list],\n",
    "                           y_pred: Union[np.ndarray, list],) -> Tuple[str, float, bool]:\n",
    "    y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n",
    "    return \"qwk\", qwk(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define validation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation():\n",
    "    def __init__(self, validation_param, exp_conf, train, test, logger):\n",
    "        self.model_name = validation_param[\"model_name\"]\n",
    "        self.train_small_dataset = exp_conf[\"train_small_dataset\"]\n",
    "#         self.common_conf = common_conf\n",
    "        self.logger = logger\n",
    "        self.exp_conf = exp_conf\n",
    "        self.train = self.fix_train_size(train)\n",
    "        self.test = test\n",
    "        self.feature_importance = []\n",
    "\n",
    "        self.logging_valid_parameters()\n",
    "\n",
    "    def logging_valid_parameters(self):\n",
    "#         self.logger.log(logging.DEBUG, self.common_conf)\n",
    "        self.logger.log(logging.DEBUG, \"[use_feature] \" + \"-\" * 50)\n",
    "        self.logger.log(logging.DEBUG, self.exp_conf[\"use_feature\"])\n",
    "        self.logger.log(logging.DEBUG, \"[train_params] \" + \"-\"*50)\n",
    "        self.logger.log(logging.DEBUG, self.exp_conf[\"train_params\"])\n",
    "\n",
    "    def fix_train_size(self, train):\n",
    "        if self.train_small_dataset:\n",
    "            self.logger.log(logging.DEBUG, \"Down-sampling train data.\")\n",
    "            self.logger.log(logging.DEBUG, f\"Org-shape:{train.shape}\")\n",
    "            p = 0.15  # 学習に使用する割合\n",
    "            np.random.seed(773)\n",
    "            int_p = int(len(train.index.values) * p)\n",
    "            sample_index = np.random.choice(train.index.values, int_p, replace=False)  # 重複なし\n",
    "\n",
    "            train = train.loc[train.index.isin(sample_index)].reset_index(drop=True)\n",
    "            self.logger.log(logging.DEBUG, f\"sampled train-shape:{train.shape}\")\n",
    "            return train\n",
    "\n",
    "        return train\n",
    "\n",
    "    def generate_model(self, model_conf):\n",
    "        if self.model_name == \"LGBM\":\n",
    "            model = LightGBM(model_conf)\n",
    "        else:\n",
    "            raise ValueError(\"permitted models are [LGBM, ..., ]\")\n",
    "        return model\n",
    "\n",
    "    def do_valid_kfold(self, model_conf, n_splits=5):\n",
    "        sp = Splitter()\n",
    "        target = model_conf[\"target\"]\n",
    "        split_x = self.train[\"installation_id\"]\n",
    "        split_y = self.train[target]\n",
    "        seed = 773\n",
    "        sp.get_kfold_idx(split_x, split_y, seed, n_cv=n_splits, stratified=False, group=True, pref=self.exp_conf[\"exp_name\"])\n",
    "\n",
    "        oof: ndarray = np.zeros((self.train.shape[0]))\n",
    "        prediction = np.zeros((self.test.shape[0]))\n",
    "\n",
    "        clf_list = []\n",
    "\n",
    "        self.logger.log(logging.DEBUG, \"[train cols] \" + \"-\"*50)\n",
    "        self.logger.log(logging.DEBUG, model_conf[\"train_cols\"])\n",
    "        self.validation_scores = []\n",
    "\n",
    "        for i, (trn_idx, val_idx) in enumerate(sp.idx_list):\n",
    "            self.logger.log(logging.DEBUG, \"-\" * 60)\n",
    "            self.logger.log(logging.DEBUG, f\"start training: {i}\")\n",
    "\n",
    "            with timer(f\"fold {i}\", self.logger):\n",
    "                train_df, valid_df = self.train.loc[trn_idx], self.train.loc[val_idx]\n",
    "                model = self.generate_model(model_conf)\n",
    "                clf, fold_oof, feature_importance_df = model.train(train_df, valid_df, self.logger)\n",
    "#                 fold_oof_class = fold_oof.argmax(axis = 1)\n",
    "                \n",
    "                fold_prediction = model.predict(self.test, self.logger)\n",
    "#                 fold_val_score = get_val_score(valid_df[target], fold_oof_class, \"QWK\")\n",
    "\n",
    "                # calc validation score using best iteration\n",
    "#                 self.validation_scores.append(fold_val_score)\n",
    "#                 self.logger.log(logging.DEBUG, f\"fold_val_score: {fold_val_score:,.5f}\")\n",
    "                \n",
    "                clf_list.append(clf)\n",
    "                oof[val_idx] = fold_oof\n",
    "\n",
    "                prediction += fold_prediction / n_splits\n",
    "\n",
    "                feature_importance_df[\"fold\"] = i\n",
    "                self.feature_importance.append(feature_importance_df)\n",
    "\n",
    "#         self.logger.log(logging.DEBUG,\n",
    "#                         f\"Total Validation Score: {sum(self.validation_scores) / len(self.validation_scores):,.5f}\")\n",
    "\n",
    "        self.feature_importance = pd.concat(self.feature_importance, axis=0)\n",
    "\n",
    "        return clf_list, oof, prediction, self.feature_importance\n",
    "\n",
    "    def do_adversarial_valid_kfold(self, model_conf, n_splits=2):\n",
    "        sp = Splitter()\n",
    "        target = \"is_test\"\n",
    "        split_x = self.train[\"installation_id\"]\n",
    "        split_y = self.train[target]\n",
    "        seed = 773\n",
    "        sp.get_kfold_idx(split_x, split_y, seed, n_cv=n_splits, stratified=True, pref=\"adv\")\n",
    "\n",
    "        target_length = 1\n",
    "        oof: ndarray = np.zeros(self.train.shape[0])\n",
    "        prediction = np.zeros(self.test.shape[0])\n",
    "\n",
    "        clf_list = []\n",
    "\n",
    "        self.logger.log(logging.DEBUG, \"[train cols] \" + \"-\"*50)\n",
    "        self.logger.log(logging.DEBUG, model_conf[\"train_cols\"])\n",
    "        self.validation_scores = []\n",
    "\n",
    "        for i, (trn_idx, val_idx) in enumerate(sp.idx_list):\n",
    "            self.logger.log(logging.DEBUG, \"-\" * 60)\n",
    "            self.logger.log(logging.DEBUG, f\"start training: {i}\")\n",
    "\n",
    "            with timer(f\"fold {i}\", self.logger):\n",
    "                train_df, valid_df = self.train.loc[trn_idx], self.train.loc[val_idx]\n",
    "                model = self.generate_model(model_conf)\n",
    "                clf, fold_oof, feature_importance_df = model.train(train_df, valid_df, self.logger)\n",
    "\n",
    "                # calc validation score using clf.best_iteration_\n",
    "                fold_val_score = get_val_score(valid_df[target], fold_oof)\n",
    "                self.validation_scores.append(fold_val_score)\n",
    "                self.logger.log(logging.DEBUG, f\"fold_val_score: {fold_val_score:,.5f}\")\n",
    "\n",
    "                clf_list.append(clf)\n",
    "                oof[val_idx] = fold_oof\n",
    "\n",
    "                feature_importance_df[\"fold\"] = i\n",
    "                self.feature_importance.append(feature_importance_df)\n",
    "\n",
    "        self.logger.log(logging.DEBUG,\n",
    "                        f\"Total Validation Score: {sum(self.validation_scores) / len(self.validation_scores):,.5f}\")\n",
    "\n",
    "        oof = np.expm1(oof)\n",
    "        self.train[\"pred_y\"] = oof\n",
    "        self.feature_importance = pd.concat(self.feature_importance, axis=0)\n",
    "\n",
    "        return clf_list, oof, prediction, self.feature_importance\n",
    "\n",
    "\n",
    "class Splitter():\n",
    "    def __init__(self):\n",
    "        self.save_dir = os.path.join(os.path.dirname(\"__file__\"), \"../data/valid_idx\")\n",
    "        self.idx_list = []\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def get_kfold_idx(self, split_x, split_y, seed, n_cv=5, stratified=True, group=False, pref=\"\"):\n",
    "        if group is False:\n",
    "            if stratified:\n",
    "                self.folds = StratifiedKFold(n_splits=n_cv, shuffle=False, random_state=seed)\n",
    "            else:\n",
    "                self.folds = KFold(n_splits=n_cv, shuffle=True, random_state=seed)\n",
    "\n",
    "            for i, (trn_, val_) in enumerate(self.folds.split(split_x, split_y)):\n",
    "                self.idx_list.append([trn_, val_])\n",
    "                idx_trn_path = os.path.join(self.save_dir, \"trn_idx_{}{}_{}.npy\".format(pref, i, seed))\n",
    "                idx_val_path = os.path.join(self.save_dir, \"val_idx_{}{}_{}.npy\".format(pref, i, seed))\n",
    "                np.save(idx_trn_path, trn_)\n",
    "                np.save(idx_val_path, val_)\n",
    "\n",
    "            return self.idx_list\n",
    "    \n",
    "        else:\n",
    "            groups = split_x\n",
    "            self.folds = GroupKFold(n_splits=n_cv)\n",
    "            for i, (trn_, val_) in enumerate(self.folds.split(split_x, split_y, groups)):\n",
    "                self.idx_list.append([trn_, val_])\n",
    "                idx_trn_path = os.path.join(self.save_dir, \"trn_idx_{}{}_{}.npy\".format(pref, i, seed))\n",
    "                idx_val_path = os.path.join(self.save_dir, \"val_idx_{}{}_{}.npy\".format(pref, i, seed))\n",
    "                np.save(idx_trn_path, trn_)\n",
    "                np.save(idx_val_path, val_)\n",
    "\n",
    "            return self.idx_list                \n",
    "        \n",
    "\n",
    "class Validation2():\n",
    "    def __init__(self, validation_param, exp_conf, train,\n",
    "                 test, logger=None, another_train=None):\n",
    "        self.model_name = validation_param[\"model_name\"]\n",
    "        self.train_small_dataset = exp_conf[\"train_small_dataset\"]\n",
    "        self.logger = logger\n",
    "        self.exp_conf = exp_conf\n",
    "        self.train = self.fix_train_size(train)\n",
    "        self.test = test\n",
    "        self.another_train = another_train\n",
    "        if another_train:\n",
    "            self.another_train_idx = np.arange(\n",
    "                len(another_train)) + len(self.train)\n",
    "            self.another_train.index = self.another_train_idx\n",
    "        self.feature_importance = []\n",
    "\n",
    "        self.logging_valid_parameters()\n",
    "\n",
    "    def logging_valid_parameters(self):\n",
    "        self.logger.log(logging.DEBUG, \"[use_feature] \" + \"-\" * 50)\n",
    "        self.logger.log(logging.DEBUG, self.exp_conf[\"use_feature\"])\n",
    "        self.logger.log(logging.DEBUG, \"[train_params] \" + \"-\" * 50)\n",
    "        self.logger.log(logging.DEBUG, self.exp_conf[\"train_params\"])\n",
    "\n",
    "    def fix_train_size(self, train):\n",
    "        if self.train_small_dataset:\n",
    "            self.logger.log(logging.DEBUG, \"Down-sampling train data.\")\n",
    "            self.logger.log(logging.DEBUG, f\"Org-shape:{train.shape}\")\n",
    "            p = 0.15  # 学習に使用する割合\n",
    "            np.random.seed(773)\n",
    "            int_p = int(len(train.index.values) * p)\n",
    "            sample_index = np.random.choice(\n",
    "                train.index.values, int_p, replace=False)  # 重複なし\n",
    "\n",
    "            train = train.loc[train.index.isin(\n",
    "                sample_index)].reset_index(drop=True)\n",
    "            self.logger.log(logging.DEBUG,\n",
    "                            f\"sampled train-shape:{train.shape}\")\n",
    "            return train\n",
    "\n",
    "        return train\n",
    "\n",
    "    def generate_model(self, model_conf):\n",
    "        if self.model_name == \"LGBM\":\n",
    "            model = LightGBM(model_conf)\n",
    "        else:\n",
    "            raise ValueError(\"permitted models are [LGBM, ..., ]\")\n",
    "        return model\n",
    "\n",
    "    def do_valid_kfold(self, model_conf, n_splits=5,\n",
    "                       trn_mode='simple', val_mode='simple'):\n",
    "        sp = Splitter()\n",
    "        target = model_conf[\"target\"]\n",
    "        split_x = self.train[\"installation_id\"]\n",
    "        split_y = self.train[target]\n",
    "        seed = 773\n",
    "        sp.get_kfold_idx(\n",
    "            split_x,\n",
    "            split_y,\n",
    "            seed,\n",
    "            n_cv=n_splits,\n",
    "            stratified=False,\n",
    "            group=True,\n",
    "            pref=self.exp_conf[\"exp_name\"])\n",
    "\n",
    "        oof: ndarray = np.zeros((self.train.shape[0]))\n",
    "        labels = np.zeros((self.train.shape[0]))\n",
    "        prediction = np.zeros((self.test.shape[0]))\n",
    "\n",
    "        clf_list = []\n",
    "\n",
    "        self.logger.log(logging.DEBUG, \"[train cols] \" + \"-\" * 50)\n",
    "        self.logger.log(logging.DEBUG, model_conf[\"train_cols\"])\n",
    "        self.validation_scores = []\n",
    "\n",
    "        for i, (trn_idx, val_idx) in enumerate(sp.idx_list):\n",
    "            self.logger.log(logging.DEBUG, \"-\" * 60)\n",
    "            self.logger.log(logging.DEBUG, f\"start training: {i}\")\n",
    "\n",
    "            with timer(f\"fold {i}\", self.logger):\n",
    "                _train = self.train.copy()\n",
    "                if self.another_train:\n",
    "                    _train = pd.concat([_train, self.another_train])\n",
    "                    trn_idx = np.concatenate([trn_idx, self.another_train_idx])\n",
    "                if trn_mode == 'simple':\n",
    "                    pass\n",
    "                elif trn_mode == 'last_truncated':\n",
    "                    trn_idx = self.get_last_trancated_idx(_train, trn_idx)\n",
    "                if val_mode == 'simple':\n",
    "                    pass\n",
    "                elif val_mode == 'last_truncated':\n",
    "                    val_idx = self.get_last_trancated_idx(_train, val_idx)\n",
    "\n",
    "                train_df, valid_df = _train.loc[trn_idx], _train.loc[val_idx]\n",
    "\n",
    "                model = self.generate_model(model_conf)\n",
    "                clf, fold_oof, feature_importance_df = model.train(\n",
    "                    train_df, valid_df, self.logger)\n",
    "#                 fold_oof_class = fold_oof.argmax(axis = 1)\n",
    "\n",
    "                fold_prediction = model.predict(self.test, self.logger)\n",
    "#                 fold_val_score = get_val_score(valid_df[target], fold_oof_class, \"QWK\")\n",
    "\n",
    "                # calc validation score using best iteration\n",
    "#                 self.validation_scores.append(fold_val_score)\n",
    "#                 self.logger.log(logging.DEBUG, f\"fold_val_score: {fold_val_score:,.5f}\")\n",
    "\n",
    "                clf_list.append(clf)\n",
    "                oof[val_idx] = fold_oof\n",
    "                labels[val_idx] = valid_df['accuracy_group'].values\n",
    "\n",
    "                prediction += fold_prediction / n_splits\n",
    "\n",
    "                feature_importance_df[\"fold\"] = i\n",
    "                self.feature_importance.append(feature_importance_df)\n",
    "\n",
    "#         self.logger.log(logging.DEBUG,\n",
    "# f\"Total Validation Score: {sum(self.validation_scores) /\n",
    "# len(self.validation_scores):,.5f}\")\n",
    "\n",
    "        self.feature_importance = pd.concat(self.feature_importance, axis=0)\n",
    "\n",
    "        return clf_list, oof, prediction, self.feature_importance, labels\n",
    "\n",
    "    def do_adversarial_valid_kfold(self, model_conf, n_splits=2):\n",
    "        sp = Splitter()\n",
    "        target = \"is_test\"\n",
    "        split_x = self.train[\"installation_id\"]\n",
    "        split_y = self.train[target]\n",
    "        seed = 773\n",
    "        sp.get_kfold_idx(\n",
    "            split_x,\n",
    "            split_y,\n",
    "            seed,\n",
    "            n_cv=n_splits,\n",
    "            stratified=True,\n",
    "            pref=\"adv\")\n",
    "\n",
    "        target_length = 1\n",
    "        oof: ndarray = np.zeros(self.train.shape[0])\n",
    "        prediction = np.zeros(self.test.shape[0])\n",
    "\n",
    "        clf_list = []\n",
    "\n",
    "        self.logger.log(logging.DEBUG, \"[train cols] \" + \"-\" * 50)\n",
    "        self.logger.log(logging.DEBUG, model_conf[\"train_cols\"])\n",
    "        self.validation_scores = []\n",
    "\n",
    "        for i, (trn_idx, val_idx) in enumerate(sp.idx_list):\n",
    "            self.logger.log(logging.DEBUG, \"-\" * 60)\n",
    "            self.logger.log(logging.DEBUG, f\"start training: {i}\")\n",
    "\n",
    "            with timer(f\"fold {i}\", self.logger):\n",
    "                train_df, valid_df = self.train.loc[trn_idx], self.train.loc[val_idx]\n",
    "                model = self.generate_model(model_conf)\n",
    "                clf, fold_oof, feature_importance_df = model.train(\n",
    "                    train_df, valid_df, self.logger)\n",
    "\n",
    "                # calc validation score using clf.best_iteration_\n",
    "                fold_val_score = get_val_score(valid_df[target], fold_oof)\n",
    "                self.validation_scores.append(fold_val_score)\n",
    "                self.logger.log(logging.DEBUG,\n",
    "                                f\"fold_val_score: {fold_val_score:,.5f}\")\n",
    "\n",
    "                clf_list.append(clf)\n",
    "                oof[val_idx] = fold_oof\n",
    "\n",
    "                feature_importance_df[\"fold\"] = i\n",
    "                self.feature_importance.append(feature_importance_df)\n",
    "\n",
    "        self.logger.log(logging.DEBUG,\n",
    "                        f\"Total Validation Score: {sum(self.validation_scores) / len(self.validation_scores):,.5f}\")\n",
    "\n",
    "        oof = np.expm1(oof)\n",
    "        self.train[\"pred_y\"] = oof\n",
    "        self.feature_importance = pd.concat(self.feature_importance, axis=0)\n",
    "\n",
    "        return clf_list, oof, prediction, self.feature_importance\n",
    "\n",
    "    def get_last_trancated_idx(self, df, idx):\n",
    "        df = df.loc[idx]\n",
    "        idx = df\\\n",
    "            .sort_values(['installation_id', 'bef_target_cnt'])\\\n",
    "            .drop_duplicates('installation_id', keep='last').index\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_feature(Features):\n",
    "    \"\"\"sample feature\n",
    "    \"\"\"\n",
    "    def __int__(self, params, logger):\n",
    "        super().__init__(params, logger)\n",
    "\n",
    "    def calc_feature(self, org_train, org_test):\n",
    "        \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "        else:\n",
    "            df = org_test\n",
    "            \n",
    "        feat_df = df.groupby(\"installation_id\")[\"title\"].count().reset_index()\n",
    "        self.format_and_save_feats(feat_df)\n",
    "        \n",
    "        return feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base kernel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class KernelBasics(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def mapping_codes(self, org_train, org_test):\n",
    "        self.all_activities = set(org_train[\"title\"].unique()).union(\n",
    "            set(org_test[\"title\"].unique()))\n",
    "        self.all_event_codes = set(org_train[\"event_code\"].unique()).union(\n",
    "            org_test[\"event_code\"].unique())\n",
    "        \n",
    "        # convert activities <=> int\n",
    "        self.activities_map = dict(\n",
    "            zip(self.all_activities, np.arange(len(self.all_activities)))) # activity title => int \n",
    "        self.inverse_activities_map = dict(\n",
    "            zip(np.arange(len(self.all_activities)), self.all_activities)) # int => activity title \n",
    "        \n",
    "        # convert win_code <=> int \n",
    "        win_code = dict(\n",
    "            zip(activities_map.values(),\n",
    "                (4100 * np.ones(len(activities_map))).astype(int)))\n",
    "        win_code[activities_map[\"Bird Measurer (Assessment)\"]] = 4110\n",
    "        \n",
    "        self.win_code = win_code\n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"true\")), 'num_correct'] = 1\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"false\")), 'num_incorrect'] = 1    \n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        \n",
    "        ret[ret_col] = ret[ret_col].fillna(0).astype(\"int32\")\n",
    "        self.format_and_save_feats(ret)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        # initialize user activity \n",
    "        # 1. time spent \n",
    "        # 2. event count \n",
    "        # 3. session count \n",
    "        \n",
    "        # sessionごとのplaytimeを算出\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "\n",
    "        pv = pd.pivot_table(df, index=[\"gs_max_time\", \"game_session\", \"type\"],  \n",
    "                            columns=\"title\", \n",
    "                            values=\"game_time\", \n",
    "                            aggfunc=\"max\").fillna(0)\n",
    "        \n",
    "        # 時刻順に並ぶことを保証する\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True)\n",
    "        \n",
    "        cum_cols = [c for c in list(pv.columns) if c not in [\"type\", \"game_session\", \"gs_max_time\"]]\n",
    "        pv[cum_cols] = (pv[cum_cols].cumsum() // 1000).astype(\"int32\")\n",
    "        pv[cum_cols] = pv[cum_cols].shift(1) # 直前までのplaytimeを取得する\n",
    "        \n",
    "        ins_id = df.installation_id.values[0]\n",
    "        \n",
    "        # assessmentのrowに限定して抽出する\n",
    "        if self.datatype == \"train\":\n",
    "            # 正解ラベル/num_corrects を得るためtrain labelsとmerge\n",
    "            pv = pd.merge(pv, self.train_labels[self.train_labels.installation_id == ins_id], how=\"inner\", on=\"game_session\")\n",
    "        else:\n",
    "            # calc num corrects \n",
    "            num_c_df = df.loc[df.type == \"Assessment\"].groupby([\"installation_id\",\"game_session\"])[[\"num_correct\", \"num_incorrect\"]].sum().fillna(0).reset_index()\n",
    "            pv = pd.merge(pv, num_c_df, how=\"left\", on=\"game_session\")\n",
    "            \n",
    "        gc.collect()\n",
    "        \n",
    "        # 直前までの正解状況を集計\n",
    "        pv[\"prev_num_corrects\"] = pv[\"num_correct\"].shift(1).fillna(0)\n",
    "        pv[\"prev_cumnum_c\"] = pv[\"prev_num_corrects\"].cumsum()\n",
    "        pv[\"prev_num_incorrects\"] = pv[\"num_incorrect\"].shift(1).fillna(0)\n",
    "        pv[\"prev_cumnum_inc\"] = pv[\"prev_num_incorrects\"].cumsum()\n",
    "\n",
    "        pv[\"cum_accuracy\"] = (pv[\"prev_cumnum_c\"] / \n",
    "                                     (pv[\"prev_cumnum_c\"] + pv[\"prev_cumnum_inc\"])).fillna(0)\n",
    "        \n",
    "        del pv[\"num_correct\"], pv[\"num_incorrect\"], pv[\"gs_max_time\"], pv[\"prev_num_corrects\"], pv[\"prev_num_incorrects\"]\n",
    "        gc.collect()\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "\n",
    "        return pv\n",
    "    \n",
    "    \n",
    "class KernelBasics2(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_labels, params, logger=None):\n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def mapping_codes(self, org_train, org_test):\n",
    "        self.all_activities = set(org_train[\"title\"].unique()).union(\n",
    "            set(org_test[\"title\"].unique()))\n",
    "        self.all_event_codes = set(org_train[\"event_code\"].unique()).union(\n",
    "            org_test[\"event_code\"].unique())\n",
    "\n",
    "        # convert activities <=> int\n",
    "        self.activities_map = dict(\n",
    "            zip(self.all_activities, np.arange(len(self.all_activities))))  # activity title => int\n",
    "        self.inverse_activities_map = dict(\n",
    "            zip(np.arange(len(self.all_activities)), self.all_activities))  # int => activity title\n",
    "\n",
    "        # convert win_code <=> int\n",
    "        win_code = dict(\n",
    "            zip(activities_map.values(),\n",
    "                (4100 * np.ones(len(activities_map))).astype(int)))\n",
    "        win_code[activities_map[\"Bird Measurer (Assessment)\"]] = 4110\n",
    "\n",
    "        self.win_code = win_code\n",
    "\n",
    "    def calc_feature(self, org_train, org_test):\n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(\n",
    "                self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            df = org_test\n",
    "\n",
    "        c_ass_idx = (((df.event_code == 4100)\n",
    "                      & (df.title != \"Bird Measurer (Assessment)\")\n",
    "                      & (df[\"event_data\"].str.contains(\"true\"))) |\n",
    "                     ((df.event_code == 4110)\n",
    "                      & (df.title == \"Bird Measurer (Assessment)\")\n",
    "                      & (df[\"event_data\"].str.contains(\"true\"))) & (df[\"type\"] == \"Assessment\"))\n",
    "\n",
    "        inc_ass_idx = (((df.event_code == 4100)\n",
    "                        & (df.title != \"Bird Measurer (Assessment)\")\n",
    "                        & (df[\"event_data\"].str.contains(\"false\"))) |\n",
    "                       ((df.event_code == 4110)\n",
    "                        & (df.title == \"Bird Measurer (Assessment)\")\n",
    "                        & (df[\"event_data\"].str.contains(\"false\"))) & (df[\"type\"] == \"Assessment\"))\n",
    "\n",
    "        df.loc[c_ass_idx, 'num_correct'] = 1\n",
    "        df.loc[inc_ass_idx, 'num_incorrect'] = 1\n",
    "\n",
    "        ret = applyParallel(\n",
    "            df.groupby(\"installation_id\"),\n",
    "            self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\", \"accuracy_group\", \"cum_accuracy\",\n",
    "                                                             \"game_session\", \"installation_id\", \"title\",\n",
    "                                                             \"type\"\n",
    "                                                             ]]\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if \"Assessment\" not in c]\n",
    "        del ret[\"accum_acc_gr_-99\"], ret[\"prev_acc_gr_-99\"]\n",
    "\n",
    "        fill_cols = [\n",
    "            c for c in list(\n",
    "                ret.columns) if c not in [\n",
    "                \"cum_accuracy\",\n",
    "                \"cum_accuracy\",\n",
    "                \"prev_num_corrects\",\n",
    "                \"prev_num_incorrects\"]]\n",
    "        ret[fill_cols] = ret[fill_cols].fillna(0)\n",
    "\n",
    "        if self.datatype == \"train\":\n",
    "            ret = pd.merge(\n",
    "                ret, self.train_labels, how=\"inner\", on=[\n",
    "                    \"installation_id\", \"game_session\"])\n",
    "\n",
    "        self.format_and_save_feats(ret)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id\n",
    "        \"\"\"\n",
    "        # initialize user activity\n",
    "        # 1. time spent\n",
    "        # 2. event count\n",
    "        # 3. session count\n",
    "\n",
    "        # sessionごとのplaytimeを算出\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\n",
    "            \"max\")  # gs_max_timeでsortする必要がある\n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"gs_max_time\", \"game_session\", \"type\"],\n",
    "                            columns=\"title\",\n",
    "                            values=\"game_time\",\n",
    "                            aggfunc=\"max\").fillna(0)\n",
    "\n",
    "        # 時刻順に並ぶことを保証する\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True)\n",
    "\n",
    "        cum_cols = [\n",
    "            c for c in list(\n",
    "                pv.columns) if c not in [\n",
    "                \"installation_id\",\n",
    "                \"type\",\n",
    "                \"game_session\",\n",
    "                \"gs_max_time\"]]\n",
    "#         pv[cum_cols] = (pv[cum_cols].cumsum() // 1000).astype(\"int32\")\n",
    "        pv[cum_cols] = (pv[cum_cols].cumsum()).fillna(0)\n",
    "        pv[cum_cols] = pv[cum_cols].shift(1)  # 直前までのplaytimeを取得する\n",
    "\n",
    "        ins_id = df.installation_id.values[0]\n",
    "        # calc num corrects\n",
    "        pv = pv.loc[pv.type == \"Assessment\"]\n",
    "        num_c_df = df.loc[(df.type == \"Assessment\") &\n",
    "                          ((df.num_correct > 0) | (df.num_incorrect > 0))].groupby([\"game_session\"])[[\"num_correct\", \"num_incorrect\"]].sum().reset_index()\n",
    "        pv = pd.merge(pv, num_c_df, how=\"left\", on=\"game_session\")\n",
    "\n",
    "        if self.datatype == \"test\":\n",
    "            last_session_name = pv.sort_values(\n",
    "                \"gs_max_time\")[\"game_session\"].values[-1]\n",
    "        else:\n",
    "            last_session_name = \"train_dummy_session\"\n",
    "\n",
    "        # train labelsのsessionは(pv.num_correct > 0) | (pv.num_incorrect >\n",
    "        # 0)を常に満たす\n",
    "        pv = pv.loc[((pv.num_correct > 0) | (pv.num_incorrect > 0))\n",
    "                    | (pv.game_session == last_session_name)]\n",
    "        gc.collect()\n",
    "\n",
    "        # 直前までの正解状況を集計\n",
    "        pv[\"prev_num_corrects\"] = pv[\"num_correct\"].shift(1)\n",
    "        pv[\"prev_num_incorrects\"] = pv[\"num_incorrect\"].shift(1)\n",
    "        pv[\"prev_cumnum_c\"] = pv[\"prev_num_corrects\"].cumsum()\n",
    "        pv[\"prev_cumnum_inc\"] = pv[\"prev_num_incorrects\"].cumsum()\n",
    "\n",
    "        pv[\"cum_accuracy\"] = (pv[\"prev_cumnum_c\"] /\n",
    "                              (pv[\"prev_cumnum_c\"] + pv[\"prev_cumnum_inc\"]))\n",
    "\n",
    "        del pv[\"num_correct\"], pv[\"num_incorrect\"]\n",
    "        gc.collect()\n",
    "\n",
    "        pv = self.get_acc_group(pv)\n",
    "        pv = pv.sort_values(\"gs_max_time\").reset_index(drop=True)\n",
    "        del pv[\"gs_max_time\"]\n",
    "\n",
    "        if self.datatype == \"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "        return pv\n",
    "\n",
    "    def get_acc_group(self, pv):\n",
    "        def calc_accuracy_group(row):\n",
    "            if row[\"prev_num_incorrects\"] + row[\"prev_num_corrects\"] > 0:\n",
    "                acc = row[\"prev_num_corrects\"] / \\\n",
    "                    (row[\"prev_num_incorrects\"] + row[\"prev_num_corrects\"])\n",
    "                if acc == 0:\n",
    "                    return 0\n",
    "                elif acc == 1:\n",
    "                    return 3\n",
    "                elif acc == 0.5:\n",
    "                    return 2\n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return -99\n",
    "\n",
    "        pv[\"acc_group\"] = pv.apply(calc_accuracy_group, axis=1)\n",
    "        acc_pv = pd.pivot_table(pv[[\"gs_max_time\",\n",
    "                                    \"installation_id\",\n",
    "                                    \"game_session\",\n",
    "                                    \"acc_group\"]],\n",
    "                                index=[\"gs_max_time\",\n",
    "                                       \"game_session\"],\n",
    "                                columns=\"acc_group\",\n",
    "                                values=\"installation_id\",\n",
    "                                aggfunc=\"count\").reset_index().fillna(0)\n",
    "        del pv[\"acc_group\"]\n",
    "\n",
    "        acc_columns = {}\n",
    "        for col in acc_pv.columns:\n",
    "            if col in [-99, 0, 1, 2, 3]:\n",
    "                acc_columns[col] = \"prev_acc_gr_\" + str(col)\n",
    "                acc_pv[f\"accum_acc_gr_{col}\"] = acc_pv[col].cumsum()\n",
    "\n",
    "        acc_pv.rename(columns=acc_columns, inplace=True)\n",
    "        del acc_pv[\"gs_max_time\"]\n",
    "        pv = pd.merge(pv, acc_pv, on=\"game_session\", how=\"left\")\n",
    "\n",
    "        return pv\n",
    "\n",
    "    def test_calc_feature(self, org_train, org_test):\n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(\n",
    "                self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            df = org_test\n",
    "#             df = org_train\n",
    "#             df = df.loc[df.installation_id.isin(self.train_labels.installation_id.unique())]\n",
    "\n",
    "        c_ass_idx = (((df.event_code == 4100)\n",
    "                      & (df.title != \"Bird Measurer (Assessment)\")\n",
    "                      & (df[\"event_data\"].str.contains(\"true\"))) |\n",
    "                     ((df.event_code == 4110)\n",
    "                      & (df.title == \"Bird Measurer (Assessment)\")\n",
    "                      & (df[\"event_data\"].str.contains(\"true\"))) & (df[\"type\"] == \"Assessment\"))\n",
    "\n",
    "        inc_ass_idx = (((df.event_code == 4100)\n",
    "                        & (df.title != \"Bird Measurer (Assessment)\")\n",
    "                        & (df[\"event_data\"].str.contains(\"false\"))) |\n",
    "                       ((df.event_code == 4110)\n",
    "                        & (df.title == \"Bird Measurer (Assessment)\")\n",
    "                        & (df[\"event_data\"].str.contains(\"false\"))) & (df[\"type\"] == \"Assessment\"))\n",
    "\n",
    "        df.loc[c_ass_idx, 'num_correct'] = 1\n",
    "        df.loc[inc_ass_idx, 'num_incorrect'] = 1\n",
    "\n",
    "        ins_df = df.loc[df.installation_id == \"0006a69f\"]\n",
    "        pv = self.ins_id_sessions(ins_df)\n",
    "\n",
    "        return pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EventCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EventCount(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"true\")), 'num_correct'] = 1\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"false\")), 'num_incorrect'] = 1    \n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0).astype(\"int32\")\n",
    "#         self.format_and_save_feats(ret)\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        \n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "\n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"gs_max_time\", \"game_session\", \"type\"],  \n",
    "                            columns=\"event_code\", \n",
    "                            values=\"timestamp\", \n",
    "                            aggfunc=\"count\").fillna(0)\n",
    "\n",
    "        # 時刻順に並ぶことを保証する\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True)\n",
    "\n",
    "        cum_cols = [c for c in list(pv.columns) if c not in [\"installation_id\", \"type\", \"game_session\", \"gs_max_time\"]]\n",
    "        pv[cum_cols] = pv[cum_cols].cumsum().shift(1).fillna(0).astype(\"int32\")\n",
    "        \n",
    "        pv = pv.loc[pv[\"type\"] == \"Assessment\"] # assessment だけとればOK\n",
    "        \n",
    "        rename_dict = {}\n",
    "        for c in cum_cols:\n",
    "            rename_dict[c] = \"ev_cnt\" + str(c)     \n",
    "        pv.rename(columns=rename_dict, inplace=True)\n",
    "        pv.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        del pv[\"gs_max_time\"], pv[\"type\"]\n",
    "        gc.collect()\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "\n",
    "        return pv\n",
    "    \n",
    "class EventCount2(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"true\")), 'num_correct'] = 1\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"false\")), 'num_incorrect'] = 1    \n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0).astype(\"int32\")\n",
    "#         self.format_and_save_feats(ret)\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        \n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "        \n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"gs_max_time\", \"game_session\", \"type\"],  \n",
    "                            columns=\"event_id\", \n",
    "                            values=\"timestamp\", \n",
    "                            aggfunc=\"count\").fillna(0)\n",
    "\n",
    "        # 時刻順に並ぶことを保証する\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True)\n",
    "\n",
    "        cum_cols = [c for c in list(pv.columns) if c not in [\"installation_id\", \"type\", \"game_session\", \"gs_max_time\"]]\n",
    "        pv[cum_cols] = pv[cum_cols].cumsum().shift(1).fillna(0).astype(\"int32\")\n",
    "        \n",
    "        pv = pv.loc[pv[\"type\"] == \"Assessment\"] # assessment だけとればOK\n",
    "        \n",
    "        rename_dict = {}\n",
    "        for c in cum_cols:\n",
    "            rename_dict[c] = \"ev_cnt\" + str(c)     \n",
    "        pv.rename(columns=rename_dict, inplace=True)\n",
    "        pv.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        del pv[\"gs_max_time\"], pv[\"type\"]\n",
    "        gc.collect()\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "\n",
    "        return pv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worldcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worldcount(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "                            \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.count_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"game_session\",\"installation_id\",\"title\",\"type\"]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0).astype(\"int32\")\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"title\",\"type\", \"event_code\", \"gs_max_time\"]]\n",
    "        \n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def count_sessions(self, df):\n",
    "        world_cnt = self.sub_count_sessions(df, [\"world\"], \"wrd_cnt_\")\n",
    "        world_type_cnt = self.sub_count_sessions(df, [\"world\", \"type\"], \"wrd_type_cnt_\")        \n",
    "        title_type_cnt = self.sub_count_sessions(df, [\"title\", \"type\"], \"title_type_cnt_\")\n",
    "        \n",
    "        world_cnt = pd.merge(world_cnt, world_type_cnt, how=\"left\", on=[\"installation_id\", \"game_session\"])\n",
    "        del world_type_cnt\n",
    "        \n",
    "        world_cnt = pd.merge(world_cnt, title_type_cnt, how=\"left\", on=[\"installation_id\", \"game_session\"])\n",
    "        del title_type_cnt        \n",
    "        \n",
    "        return world_cnt\n",
    "    \n",
    "    def sub_count_sessions(self, df, group_columns, prefix):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"        \n",
    "        assess_sessions = df[df.type == \"Assessment\"][\"game_session\"].unique()\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "\n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"gs_max_time\", \"game_session\"],  \n",
    "                            columns=group_columns, \n",
    "                            values=\"timestamp\", \n",
    "                            aggfunc=\"count\").fillna(0)\n",
    "\n",
    "        # 時刻順に並ぶことを保証する\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True)\n",
    "        \n",
    "        if len(group_columns) >= 2:\n",
    "            pv.columns = [c[0] + \"_\" + c[1] for c in pv.columns] \n",
    "            pv.rename(columns={\"installation_id_\": \"installation_id\", \n",
    "                               \"game_session_\": \"game_session\", \n",
    "                               \"gs_max_time_\": \"gs_max_time\"\n",
    "                              }, inplace=True)\n",
    "\n",
    "        cum_cols = [c for c in list(pv.columns) if c not in [\"installation_id\", \"game_session\", \"gs_max_time\"]]\n",
    "        pv[cum_cols] = pv[cum_cols].cumsum().shift(1).fillna(0).astype(\"int32\")\n",
    "\n",
    "\n",
    "        rename_dict = {}\n",
    "        for c in cum_cols:\n",
    "            rename_dict[c] = prefix + str(c)     \n",
    "        pv.rename(columns=rename_dict, inplace=True)\n",
    "        pv.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        del pv[\"gs_max_time\"]\n",
    "        gc.collect()\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "        elif self.datatype ==\"train\":\n",
    "            pv = pv.loc[pv.game_session.isin(assess_sessions)]\n",
    "\n",
    "        return pv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SessionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionTime(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "                            \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.time_sessions)\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"title\",\"type\", \"world\",\n",
    "                                                              \"event_code\", \"gs_max_time\", \"timestamp_max\", \"timestamp_min\"]]\n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def count_sessions(self, df):\n",
    "        world_cnt = self.sub_count_sessions(df, [\"world\"], \"wrd_cnt_\")\n",
    "        world_type_cnt = self.sub_count_sessions(df, [\"world\", \"type\"], \"wrd_type_cnt_\")        \n",
    "        title_type_cnt = self.sub_count_sessions(df, [\"title\", \"type\"], \"title_type_cnt_\")\n",
    "        \n",
    "        world_cnt = pd.merge(world_cnt, world_type_cnt, how=\"left\", on=[\"installation_id\", \"game_session\"])\n",
    "        del world_type_cnt\n",
    "        \n",
    "        world_cnt = pd.merge(world_cnt, title_type_cnt, how=\"left\", on=[\"installation_id\", \"game_session\"])\n",
    "        del title_type_cnt        \n",
    "        \n",
    "        return world_cnt\n",
    "    \n",
    "    def time_sessions(self, ins_df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"        \n",
    "        agg_dict = {\n",
    "            \"timestamp\" : [\"max\", \"min\"]\n",
    "        }\n",
    "        duration_df = groupings(ins_df, [\"installation_id\", \"world\", \"type\", \"game_session\"], agg_dict).sort_values(\"timestamp_min\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "        duration_df[\"prev_gs_duration\"] = (duration_df[\"timestamp_max\"] - duration_df[\"timestamp_min\"]).shift(1).dt.total_seconds()\n",
    "        duration_df[\"session_interval\"] = (duration_df[\"timestamp_min\"] - duration_df[\"timestamp_max\"].shift(1)).dt.total_seconds()\n",
    "        \n",
    "        window = 25\n",
    "        min_periods = 5\n",
    "        for col in [\"prev_gs_duration\", \"session_interval\"]:\n",
    "            duration_df[col + \"rmean\"] = duration_df[col].rolling(window=window, min_periods=min_periods).mean()\n",
    "            duration_df[col + \"rstd\"] = duration_df[col].rolling(window=window, min_periods=min_periods).std()\n",
    "            duration_df[col + \"rmax\"] = duration_df[col].rolling(window=window, min_periods=2).max()\n",
    "            duration_df[col + \"rmin\"] = duration_df[col].rolling(window=window, min_periods=2).min()        \n",
    "            \n",
    "        duration_df = duration_df.loc[duration_df.type == \"Assessment\"]\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            duration_df = pd.DataFrame([duration_df.iloc[-1, :]])\n",
    "\n",
    "        return duration_df\n",
    "    \n",
    "    \n",
    "class SessionTime2(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "                            \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.time_sessions)\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"title\",\"type\", \"world\",\n",
    "                                                              \"event_code\", \"gs_max_time\", \"timestamp_max\", \"timestamp_min\"]]\n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def time_sessions(self, ins_df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"        \n",
    "        ### session feature for all \"type\"\n",
    "        agg_dict = {\n",
    "            \"timestamp\" : [\"max\", \"min\"]\n",
    "        }\n",
    "        duration_df = groupings(ins_df, [\"installation_id\", \"world\", \"type\", \"game_session\"], agg_dict).sort_values(\"timestamp_min\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "        duration_df[\"prev_gs_duration\"] = (duration_df[\"timestamp_max\"] - duration_df[\"timestamp_min\"]).shift(1).dt.total_seconds()\n",
    "        duration_df[\"session_interval\"] = (duration_df[\"timestamp_min\"] - duration_df[\"timestamp_max\"].shift(1)).dt.total_seconds()\n",
    "        \n",
    "        window = 5\n",
    "        min_periods = 2\n",
    "        for col in [\"prev_gs_duration\", \"session_interval\"]:\n",
    "            duration_df[col + \"rmean\"] = duration_df[col].rolling(window=window, min_periods=min_periods).mean()\n",
    "            duration_df[col + \"rstd\"] = duration_df[col].rolling(window=window, min_periods=min_periods).std()\n",
    "            duration_df[col + \"rmax\"] = duration_df[col].rolling(window=window, min_periods=2).max()\n",
    "            duration_df[col + \"rmin\"] = duration_df[col].rolling(window=window, min_periods=2).min()        \n",
    "            \n",
    "        duration_df = duration_df.loc[duration_df.type == \"Assessment\"]\n",
    "        \n",
    "        ### session feature for \"assessments\"        \n",
    "        agg_dict = {\n",
    "            \"timestamp\" : [\"max\", \"min\"]\n",
    "        }\n",
    "        ass_duration = groupings(ins_df, [\"installation_id\", \"world\", \"type\", \"game_session\"], agg_dict)\n",
    "        ass_duration = ass_duration.loc[ass_duration.type == \"Assessment\"].sort_values(\"timestamp_min\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "        ass_duration[\"prev_ass_gs_duration\"] = (ass_duration[\"timestamp_max\"] - ass_duration[\"timestamp_min\"]).shift(1).dt.total_seconds()\n",
    "        ass_duration[\"ass_session_interval\"] = (ass_duration[\"timestamp_min\"] - ass_duration[\"timestamp_max\"].shift(1)).dt.total_seconds()\n",
    "\n",
    "        window = 5\n",
    "        min_periods = 1\n",
    "        for col in [\"prev_ass_gs_duration\", \"ass_session_interval\"]:\n",
    "            ass_duration[col + \"_rmean\"] = ass_duration[col].rolling(window=window, min_periods=min_periods).mean()\n",
    "            ass_duration[col + \"_rstd\"] = ass_duration[col].rolling(window=window, min_periods=min_periods).std()\n",
    "            ass_duration[col + \"_rmax\"] = ass_duration[col].rolling(window=window, min_periods=1).max()\n",
    "            ass_duration[col + \"_rmin\"] = ass_duration[col].rolling(window=window, min_periods=1).min()        \n",
    "        \n",
    "        ass_cols = [c for c in list(ass_duration.columns) if c not in ['installation_id', 'world', 'type','timestamp_max','timestamp_min']]\n",
    "        \n",
    "        duration_df = pd.merge(duration_df, ass_duration[ass_cols], how=\"left\", on=\"game_session\")\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            duration_df = pd.DataFrame([duration_df.iloc[-1, :]])\n",
    "\n",
    "        return duration_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncodingTitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingTitles(Features):\n",
    "    \"\"\"Event count in only Assessments\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def get_encoder(self, org_train, org_test):\n",
    "        self.all_activities = np.sort(list(set(org_train[\"title\"].unique()).union(\n",
    "            set(org_test[\"title\"].unique()))))\n",
    "        # self.all_activities = set(org_train[\"title\"].unique()).union(\n",
    "        #     set(org_test[\"title\"].unique()))\n",
    "        self.all_event_codes = set(org_train[\"event_code\"].unique()).union(\n",
    "            org_test[\"event_code\"].unique())\n",
    "        self.activities_map = dict(\n",
    "            zip(self.all_activities, np.arange(len(self.all_activities))))\n",
    "        self.inverse_activities_map = dict(\n",
    "            zip(np.arange(len(self.all_activities)), self.all_activities))\n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"true\")), 'num_correct'] = 1\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"false\")), 'num_incorrect'] = 1    \n",
    "            df = org_test\n",
    "        \n",
    "        # get encodings informations\n",
    "        self.get_encoder(org_train, org_test)\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        \n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        df[\"title_enc\"] = df[\"title\"].map(self.activities_map)\n",
    "        df = df.loc[df.type==\"Assessment\"][[\"installation_id\", \"game_session\", \"title_enc\"]].drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            df = pd.DataFrame([df.iloc[-1, :]])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrevAssessResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrevAssessResult(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"true\")), 'num_correct'] = 1\n",
    "            org_test.loc[(org_test.event_code.isin([4100, 4110])) & (org_test[\"event_data\"].str.contains(\"false\")), 'num_incorrect'] = 1    \n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0).astype(\"int32\")\n",
    "#         self.format_and_save_feats(ret)\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        \n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "    \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        # 単純なactivity count\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"gs_max_time\", \"game_session\", \"type\"],  \n",
    "                            columns=\"title\", \n",
    "                            values=\"timestamp\", \n",
    "                            aggfunc=\"count\").fillna(0)\n",
    "\n",
    "\n",
    "        assess_col = [c for c in list(pv.columns) if \"Assessment\" in c]\n",
    "        pv = pv[assess_col]\n",
    "        pv.reset_index(inplace=True)\n",
    "\n",
    "        rename_dict = {}\n",
    "        new_cols = []\n",
    "        \n",
    "        cnt_pref = \"assess_cnt_\"\n",
    "        for c in assess_col:\n",
    "            rename_dict[c] = cnt_pref + str(c)     \n",
    "\n",
    "        pv = pv.loc[pv.type==\"Assessment\"].reset_index(drop=True)\n",
    "        pv.sort_values(\"gs_max_time\", ascending=True, inplace=True)\n",
    "        pv.reset_index(inplace=True, drop=True)\n",
    "        pv[assess_col] = pv[assess_col].shift(1).fillna(0)\n",
    "        pv.rename(columns=rename_dict, inplace=True)\n",
    "        \n",
    "        for c in assess_col:\n",
    "            pv[\"accum\" + cnt_pref + str(c)] = pv[cnt_pref + str(c)].cumsum()\n",
    "\n",
    "        del pv[\"gs_max_time\"], pv[\"type\"]\n",
    "\n",
    "        return pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrevAssessAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_history(gr_df):\n",
    "    gr_df = gr_df.sort_values(\"gs_max_time\", ascending=True)\n",
    "\n",
    "    gr_df[\"as_acc_c_num\"] = gr_df[\"num_correct\"].cumsum()\n",
    "    gr_df[\"as_acc_inc_num\"] = gr_df[\"num_incorrect\"].cumsum()\n",
    "    gr_df[\"as_prev_acc\"] = gr_df[\"num_correct\"] / (gr_df[\"num_correct\"] + gr_df[\"num_incorrect\"])\n",
    "    gr_df[\"as_cum_acc\"] = gr_df[\"as_acc_c_num\"] / (gr_df[\"as_acc_c_num\"] + gr_df[\"as_acc_inc_num\"])\n",
    "\n",
    "    shift_col = [\"num_correct\", \"num_incorrect\", \"as_acc_c_num\", \"as_acc_inc_num\", \"as_prev_acc\", \"as_cum_acc\"]\n",
    "    gr_df[shift_col] = gr_df[shift_col].shift(1).fillna(-99)\n",
    "\n",
    "    return gr_df    \n",
    "\n",
    "class PrevAssessAcc(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            assess_user = df.loc[df.type == \"Assessment\"].installation_id.unique()\n",
    "            df = df.loc[df.installation_id.isin(assess_user)]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0)\n",
    "#         self.format_and_save_feats(ret)\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "        \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        # 単純なactivity count\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "        \n",
    "        c_ass_idx = ((df.event_code == 4100) \n",
    "                          & (df.title != \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"true\"))) | \\\n",
    "                         ((df.event_code == 4110) \n",
    "                          & (df.title == \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"true\")))\n",
    "\n",
    "        inc_ass_idx = ((df.event_code == 4100) \n",
    "                          & (df.title != \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"false\"))) | \\\n",
    "                         ((df.event_code == 4110) \n",
    "                          & (df.title == \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"false\")))\n",
    "\n",
    "        df.loc[c_ass_idx, 'num_correct'] = 1\n",
    "        df.loc[inc_ass_idx, 'num_incorrect'] = 1\n",
    "\n",
    "        df[\"num_correct\"].fillna(0, inplace=True)\n",
    "        df[\"num_incorrect\"].fillna(0, inplace=True)\n",
    "\n",
    "        df = df.loc[(df.type ==\"Assessment\")]\n",
    "        \n",
    "        df = df.groupby([\"installation_id\", \"game_session\", \"gs_max_time\", \"title\"])[[\"num_correct\", \"num_incorrect\"]].sum().reset_index()\n",
    "               \n",
    "        df = df.groupby(\"title\").apply(assess_history)\n",
    "        df = df.sort_values(\"gs_max_time\", ascending=True)\n",
    "\n",
    "        del df[\"title\"], df[\"gs_max_time\"]\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            df = pd.DataFrame([df.iloc[-1, :]])\n",
    "       \n",
    "        return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrevAssessAccByTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrevAssessAccByTitle(Features):\n",
    "    \"\"\"kernel features revised\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        ret[ret_col] = ret[ret_col].fillna(0)\n",
    "#         self.format_and_save_feats(ret)\n",
    "\n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "        \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"session当該session直前までのactivityを示す\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        # 単純なactivity count\n",
    "        df[\"gs_max_time\"] = df.groupby(\"game_session\")[\"timestamp\"].transform(\"max\") # gs_max_timeでsortする必要がある\n",
    "        \n",
    "        c_ass_idx = ((df.event_code == 4100) \n",
    "                          & (df.title != \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"true\"))) | \\\n",
    "                         ((df.event_code == 4110) \n",
    "                          & (df.title == \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"true\")))\n",
    "\n",
    "        inc_ass_idx = ((df.event_code == 4100) \n",
    "                          & (df.title != \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"false\"))) | \\\n",
    "                         ((df.event_code == 4110) \n",
    "                          & (df.title == \"Bird Measurer (Assessment)\") \n",
    "                          & (df[\"event_data\"].str.contains(\"false\")))\n",
    "\n",
    "        df.loc[c_ass_idx, 'num_correct'] = 1\n",
    "        df.loc[inc_ass_idx, 'num_incorrect'] = 1\n",
    "\n",
    "        df[\"num_correct\"].fillna(0, inplace=True)\n",
    "        df[\"num_incorrect\"].fillna(0, inplace=True)\n",
    "\n",
    "        df = df.loc[(df.type ==\"Assessment\")]\n",
    "        \n",
    "        pv = pd.pivot_table(df, index=[\"installation_id\", \"game_session\", \"gs_max_time\"], columns=\"title\", values=[\"num_correct\", \"num_incorrect\"], aggfunc=\"sum\").reset_index().sort_values(\"gs_max_time\")\n",
    "\n",
    "        pv.columns = [c[0] + \"_\" + c[1] if c[1] != \"\" else c[0] for c in list(pv.columns)]\n",
    "        pv_num_cols = [c for c in list(pv.columns) if \"correct\" in c]\n",
    "\n",
    "        cum_cols = [\"cum_\" + c for c in pv_num_cols] # 累積列\n",
    "\n",
    "        pv_cum_corr_cols = [c for c in cum_cols if \"cum_num_correct_\" in c] # correct 列のみ \n",
    "        pv_cum_incorr_cols = [c for c in cum_cols if \"cum_num_incorrect_\" in c] # incorrect 列\n",
    "        pv_cum_acc_cols = [\"cum_acc_\" + re.sub('num_incorrect_', '', c) for c in pv_cum_incorr_cols]\n",
    "\n",
    "        pv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        pv[pv_num_cols] = pv[pv_num_cols].shift(1).fillna(0)\n",
    "        pv[cum_cols] = pv[pv_num_cols].cumsum()\n",
    "\n",
    "        pv[pv_cum_acc_cols] = pd.DataFrame(pv[pv_cum_corr_cols].values / (pv[pv_cum_corr_cols].values + pv[pv_cum_incorr_cols].values))\n",
    "\n",
    "        del pv[\"gs_max_time\"]\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            pv = pd.DataFrame([pv.iloc[-1, :]])\n",
    "       \n",
    "        return pv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GameDurMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_duration(val):\n",
    "    val = json.loads(val)\n",
    "    duration = val[\"duration\"]\n",
    "    g_misses = val[\"misses\"]\n",
    "    \n",
    "    return [duration, g_misses]\n",
    "\n",
    "def world_cum_duration_calc(world_df):\n",
    "    # duration / missを抽出\n",
    "    wg_df = world_df[(world_df.event_code == 2030) & (world_df.type==\"Game\")]\n",
    "    du_miss = np.array(wg_df[\"event_data\"].apply(game_duration).tolist())\n",
    "    try:\n",
    "        wg_df[\"duration\"] = du_miss[:, 0]\n",
    "        wg_df[\"misses\"] = du_miss[:, 1]\n",
    "    except:\n",
    "        wg_df[\"duration\"] = np.nan\n",
    "        wg_df[\"misses\"] = np.nan\n",
    "\n",
    "    del du_miss\n",
    "\n",
    "    aggs = {\n",
    "        \"duration\": [\"min\", \"mean\", \"max\", \"std\", \"count\"],\n",
    "        \"misses\": [\"min\", \"mean\", \"max\", \"std\"],\n",
    "    }\n",
    "\n",
    "    game_cums = groupings(wg_df, [\"game_session\", \"gs_max_time\", \"world\"], aggs, \"g_\")\n",
    "\n",
    "    del wg_df\n",
    "    gc.collect()\n",
    "\n",
    "    # 累積を計算\n",
    "    game_cums = game_cums.sort_values(\"gs_max_time\").reset_index(drop=True)\n",
    "\n",
    "    num_cols = [c for c in list(game_cums.columns) if c not in [\"game_session\", \"gs_max_time\", \"world\"] ]\n",
    "    cum_mean_cols = [\"mean_\" + c for c in num_cols]\n",
    "\n",
    "    game_cums[cum_mean_cols] = game_cums[num_cols].cumsum()\n",
    "    game_cums[\"cumnum\"] = (game_cums.index + 1).values\n",
    "    game_cums[cum_mean_cols] /= game_cums[\"cumnum\"].values.reshape((-1, 1))\n",
    "\n",
    "    game_cums[[\"game_session\", \"gs_max_time\", \"world\"] + cum_mean_cols]\n",
    "\n",
    "    # 直前のgameまでの累積結果をmergeする\n",
    "    game_ass_uni = world_df[[\"world\", \"game_session\", \"type\", \"installation_id\",\"gs_max_time\"]].drop_duplicates().sort_values(\"gs_max_time\").reset_index(drop=True)\n",
    "\n",
    "    game_ass_uni = pd.merge(game_ass_uni, game_cums, how=\"left\", on=[\"game_session\", \"gs_max_time\", \"world\"]).fillna(method=\"ffill\")\n",
    "    game_ass_uni = game_ass_uni.loc[game_ass_uni.type==\"Assessment\"]\n",
    "\n",
    "    return game_ass_uni\n",
    "\n",
    "class GameDurMiss(Features):\n",
    "    \"\"\"assessment 直前までのgameのプレイ状況を取得する\n",
    "    \"\"\"\n",
    "    def __init__(self, train_labels, params, logger=None):        \n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels        \n",
    "        \n",
    "    def calc_feature(self, org_train, org_test):                \n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "        \n",
    "        ret = applyParallel(df.groupby(\"installation_id\"), self.ins_id_sessions)\n",
    "        ret_col = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\n",
    "                                                             \"game_session\",\"installation_id\",\"title\",\n",
    "                                                             \"type\"\n",
    "                                                            ]]\n",
    "        \n",
    "        use_cols = [c for c in list(ret.columns) if c not in [\"accuracy\",\"accuracy_group\",\"cum_accuracy\",\"title\",\n",
    "                                                             \"type\", \"event_code\", \"gs_max_time\"\n",
    "                                                            ]]\n",
    "        self.format_and_save_feats(ret[use_cols])\n",
    "        \n",
    "        return ret[use_cols]\n",
    "        \n",
    "    def ins_id_sessions(self, df):\n",
    "        \"\"\"assessment 直前までのgameのプレイ状況を取得する\n",
    "        Args:\n",
    "            df: df grouped by installation_id \n",
    "        \"\"\"\n",
    "        # 単純なactivity count\n",
    "        gs_game_ass = df.loc[((df.event_code == 2030) & (df.type==\"Game\")) | (df.type==\"Assessment\")]\n",
    "        gs_game_ass[\"gs_max_time\"] = gs_game_ass.groupby(\"game_session\")[\"timestamp\"].transform(\"max\")        \n",
    "        \n",
    "        game_ass_uni = gs_game_ass.groupby(\"world\").apply(world_cum_duration_calc).reset_index(drop=True).sort_values(\"gs_max_time\")\n",
    "        \n",
    "        del gs_game_ass\n",
    "        \n",
    "        if self.datatype==\"test\":\n",
    "            game_ass_uni = pd.DataFrame([game_ass_uni.iloc[-1, :]])\n",
    "       \n",
    "        return game_ass_uni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shift features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class immediatelyBeforeFeatures(Features):\n",
    "    \"\"\"\n",
    "    date features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_labels, params, logger=None):\n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_encoder(self, org_train, org_test):\n",
    "        self.all_activities = np.sort(list(set(org_train[\"title\"].unique()).union(\n",
    "            set(org_test[\"title\"].unique()))))\n",
    "        self.all_event_codes = np.sort(list(set(org_train[\"event_code\"].unique()).union(\n",
    "            set(org_test[\"event_code\"].unique()))))\n",
    "        # self.all_activities = set(org_train[\"title\"].unique()).union(\n",
    "        #     set(org_test[\"title\"].unique()))\n",
    "        # self.all_event_codes = set(org_train[\"event_code\"].unique()).union(\n",
    "        #     org_test[\"event_code\"].unique())\n",
    "        self.activities_map = dict(\n",
    "            zip(self.all_activities, np.arange(len(self.all_activities))))\n",
    "        self.inverse_activities_map = dict(\n",
    "            zip(np.arange(len(self.all_activities)), self.all_activities))\n",
    "\n",
    "    def calc_feature(self, org_train, org_test):\n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(\n",
    "                self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "\n",
    "        # get encodings informations\n",
    "        self.get_encoder(org_train, org_test)\n",
    "\n",
    "        ret = applyParallel(\n",
    "            df.groupby(\"installation_id\"),\n",
    "            self._calc_features)\n",
    "\n",
    "        self.format_and_save_feats(ret)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _calc_features(self, df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        SHIFT = 1\n",
    "\n",
    "        # game session 毎に feature を作る\n",
    "        df = df.sort_values(['game_session', 'timestamp'])\\\n",
    "            .reset_index(drop=True)\n",
    "        grp_features_df = df.groupby(['installation_id', 'game_session']).agg(\n",
    "            {\n",
    "                'timestamp': ['max', ],\n",
    "                'event_count': ['max'],\n",
    "                'event_code': {\n",
    "                    'last': lambda x: x.iloc[-1]\n",
    "                },\n",
    "                'game_time': {\n",
    "                    'max': 'max',\n",
    "                    'skew': 'skew',\n",
    "                    'kurt': lambda x: x.kurt(),\n",
    "#                    'diff_mean': lambda x: x.diff().mean(),\n",
    "#                    'diff_std': lambda x: x.diff().std()\n",
    "#                    'diff_skew': lambda x: x.diff().skew()\n",
    "#                    'diff_kurt': lambda x: x.diff().kurt()\n",
    "                },\n",
    "                'title': {\n",
    "                    'LE': lambda x: self.activities_map[x.iloc[-1]],\n",
    "                },\n",
    "                'type': {\n",
    "                    'LE': lambda x: {\n",
    "                        'Game': 0,\n",
    "                        'Activity': 1,\n",
    "                        'Assessment': 2,\n",
    "                        'Clip': 3,\n",
    "                    }[x.iloc[-1]]\n",
    "                },\n",
    "                'world': {\n",
    "                    'LE': lambda x: {\n",
    "                        'MAGMAPEAK': 0,\n",
    "                        'TREETOPCITY': 1,\n",
    "                        'CRYSTALCAVES': 2,\n",
    "                        'NONE': 3,\n",
    "                    }[x.iloc[-1]]\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        # col 調整\n",
    "        grp_features_df.columns = [\n",
    "            f'{col[0]}_{col[1]}' for col in grp_features_df.columns]\n",
    "        # session 順を保証\n",
    "        grp_features_df = grp_features_df.sort_values('timestamp_max')\n",
    "        grp_features_df = grp_features_df.drop('timestamp_max', axis=1)\n",
    "\n",
    "        # shift\n",
    "#            .set_index(['installation_id', 'game_session'])\\\n",
    "        res_grp_features_df = grp_features_df\\\n",
    "            .add_prefix(f'{SHIFT}th_before_session_')\\\n",
    "            .shift(SHIFT)\\\n",
    "            .reset_index()\n",
    "\n",
    "        return res_grp_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## world game numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class worldGameNumeriacalFeatures(Features):\n",
    "    def __init__(self, train_labels, params, logger=None):\n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_encoder(self, org_train, org_test):\n",
    "        self.all_event_codes = set(org_train[\"event_code\"].unique()).union(\n",
    "            org_test[\"event_code\"].unique())\n",
    "        self.inverse_activities_map = self.media_sequence.title.to_dict()\n",
    "        self.activities_map = {v: k for k,\n",
    "                               v in self.inverse_activities_map.items()}\n",
    "\n",
    "    def calc_feature(self, org_train, org_test):\n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(\n",
    "                self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # 直前までのnum_correct/incorrectを取得する\n",
    "            df = org_test\n",
    "\n",
    "        c_ass_idx = ((df.type == \"Game\")\n",
    "                     & (df[\"event_data\"].str.contains(\"true\"))) | \\\n",
    "            ((df.type == \"Assesment\")\n",
    "             & (df[\"event_data\"].str.contains(\"true\")))\n",
    "\n",
    "        inc_ass_idx = ((df.type == \"Game\")\n",
    "                       & (df[\"event_data\"].str.contains(\"false\"))) | \\\n",
    "            ((df.type == \"Assesment\")\n",
    "             & (df[\"event_data\"].str.contains(\"false\")))\n",
    "\n",
    "        df.loc[c_ass_idx, 'num_correct'] = 1\n",
    "        df.loc[inc_ass_idx, 'num_incorrect'] = 1\n",
    "\n",
    "        ret = applyParallel(\n",
    "            df.groupby(\"installation_id\"),\n",
    "            self._calc_features)\n",
    "\n",
    "        self.format_and_save_feats(ret)\n",
    "        return ret\n",
    "\n",
    "    def _calc_features(self, df):\n",
    "        grp_df = df.groupby(['installation_id', 'game_session', 'world']).agg(\n",
    "            {\n",
    "                'timestamp': ['max', ],\n",
    "                'num_correct': ['sum'],\n",
    "                'num_incorrect': ['sum'],\n",
    "                'game_time': ['max', 'std'],\n",
    "                'event_count': ['max'],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        grp_df.columns = [\n",
    "            f'{col[0]}_{col[1]}' for col in grp_df.columns]\n",
    "\n",
    "        grp_df['accuracy'] = grp_df['num_correct_sum'] / \\\n",
    "            (grp_df['num_correct_sum'] + grp_df['num_incorrect_sum'])\n",
    "\n",
    "        grp_df = grp_df.sort_values('timestamp_max')\n",
    "        grp_df = grp_df.drop('timestamp_max', axis=1)\n",
    "        grp_df = grp_df.shift(1)\n",
    "        grp_df = grp_df.reset_index()\n",
    "\n",
    "        res_df = grp_df[['installation_id', 'game_session']]\n",
    "\n",
    "        for world in ['MAGMAPEAK', 'CRYSTALCAVES', 'TREETOPCITY', 'NONE']:\n",
    "            _df = grp_df.copy()\n",
    "            _df.loc[_df.world != world, 'accuracy'] = None\n",
    "\n",
    "            res_df[f'{world}_accuracy_max'] = \\\n",
    "                _df['accuracy'].rolling(\n",
    "                window=len(_df), min_periods=1).max()\n",
    "            res_df[f'{world}_accuracy_min'] = \\\n",
    "                _df['accuracy'].rolling(\n",
    "                window=len(_df), min_periods=1).min()\n",
    "            res_df[f'{world}_accuracy_mean'] = \\\n",
    "                _df['accuracy'].rolling(\n",
    "                window=len(_df), min_periods=1).mean()\n",
    "            res_df[f'{world}_accuracy_std'] = \\\n",
    "                _df['accuracy'].rolling(\n",
    "                window=len(_df), min_periods=1).std()\n",
    "            res_df[f'{world}_just_before_accuracy'] = \\\n",
    "                _df['accuracy'].rolling(\n",
    "                window=len(_df), min_periods=1).apply(\n",
    "                lambda x: pd.Series(x).dropna().iloc[-1])\n",
    "\n",
    "        worlds = ['MAGMAPEAK', 'CRYSTALCAVES', 'TREETOPCITY', 'NONE']\n",
    "        res_df['world_accracy_mean_mean'] = res_df[[\n",
    "            f'{world}_accuracy_mean' for world in worlds]].mean(axis=1).values\n",
    "        res_df['world_accracy_mean_std'] = res_df[[\n",
    "            f'{world}_accuracy_mean' for world in worlds]].std(axis=1).values\n",
    "        res_df['world_accracy_max_max'] = res_df[[\n",
    "            f'{world}_accuracy_max' for world in worlds]].max(axis=1).values\n",
    "        res_df['world_accracy_max_mean'] = res_df[[\n",
    "            f'{world}_accuracy_max' for world in worlds]].mean(axis=1).values\n",
    "        res_df['world_accracy_max_std'] = res_df[[\n",
    "            f'{world}_accuracy_max' for world in worlds]].std(axis=1).values\n",
    "        res_df['world_accracy_min_min'] = res_df[[\n",
    "            f'{world}_accuracy_min' for world in worlds]].min(axis=1).values\n",
    "        res_df['world_accracy_min_mean'] = res_df[[\n",
    "            f'{world}_accuracy_min' for world in worlds]].mean(axis=1).values\n",
    "        res_df['world_accracy_min_std'] = res_df[[\n",
    "            f'{world}_accuracy_min' for world in worlds]].std(axis=1).values\n",
    "        res_df['world_accracy_std_mean'] = res_df[[\n",
    "            f'{world}_accuracy_std' for world in worlds]].mean(axis=1).values\n",
    "        res_df['world_accracy_std_std'] = res_df[[\n",
    "            f'{world}_accuracy_std' for world in worlds]].std(axis=1).values\n",
    "\n",
    "        if self.datatype == \"test\":\n",
    "            res_df = pd.DataFrame([res_df.iloc[-1, :]])\n",
    "        else:\n",
    "            # to save memory\n",
    "            res_df = res_df[\n",
    "                res_df.game_session\n",
    "                .isin(self.train_labels.game_session)\n",
    "            ]\n",
    "\n",
    "        res_df = res_df\\\n",
    "            .set_index(['installation_id', 'game_session'])\\\n",
    "            .add_prefix(f'worldwise_game_')\\\n",
    "            .reset_index()\n",
    "\n",
    "        return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target count feature (need for truncated val!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class befTargetCntFeatures(Features):\n",
    "    def __init__(self, train_labels, params, logger=None):\n",
    "        super().__init__(params, logger=logger)\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def calc_feature(self, org_train, org_test):\n",
    "        if self.datatype == \"train\":\n",
    "            df = org_train\n",
    "            df = df.loc[df.installation_id.isin(\n",
    "                self.train_labels.installation_id.unique())]\n",
    "        else:\n",
    "            # \u001b$BD>A0$^$G$N\u001b(Bnum_correct/incorrect\u001b$B$r<hF@$9$k\u001b(B\n",
    "            df = org_test\n",
    "\n",
    "        ret = applyParallel(\n",
    "            df.groupby(\"installation_id\"),\n",
    "            self._calc_features)\n",
    "\n",
    "        self.format_and_save_feats(ret)\n",
    "        return ret\n",
    "\n",
    "    def _calc_features(self, df):\n",
    "        df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "        df['test_last'] = 0\n",
    "        if self.datatype == 'test':\n",
    "            df.loc[df.shape[0]-1, 'test_last'] = 1\n",
    "\n",
    "        df = df[\n",
    "            ((df.type == 'Assessment')\n",
    "             & (\n",
    "                ((df.event_code == 4100)\n",
    "                 & (df.title != 'Bird Measurer (Assessment)'))\n",
    "                | ((df.event_code == 4110)\n",
    "                   & (df.title == 'Bird Measurer (Assessment)'))\n",
    "            ))\n",
    "            | (df.test_last == 1)\n",
    "        ]\n",
    "\n",
    "        res_df = df.groupby(['installation_id', 'game_session']).agg(\n",
    "            {\n",
    "                'timestamp': ['max'],\n",
    "            }\n",
    "        )\n",
    "        res_df.columns = [f'{col[0]}_{col[1]}' for col in res_df.columns]\n",
    "        res_df = res_df.sort_values('timestamp_max')\n",
    "        res_df['bef_target_cnt'] = res_df.rolling(\n",
    "            window=len(res_df), min_periods=1).count().values\n",
    "        res_df = res_df.drop(['timestamp_max'], axis=1)\n",
    "        res_df = res_df.reset_index()\n",
    "\n",
    "        if self.datatype == \"test\":\n",
    "            res_df = pd.DataFrame([res_df.iloc[-1, :]])\n",
    "        else:\n",
    "            # to save memory\n",
    "            res_df = res_df[\n",
    "                res_df.game_session\n",
    "                .isin(self.train_labels.game_session)\n",
    "            ]\n",
    "\n",
    "        return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -qwk(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']\n",
    "\n",
    "    \n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, cohen_kappa_score\n",
    "class OptimizedRounder_v2(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return -cohen_kappa_score(y, preds, weights = 'quadratic')\n",
    "    def fit(self, X, y, method = 'nelder-mead'):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = [1.0, 1.5, 2.0]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method=method)\n",
    "    def predict(self, X, coef):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "        return preds\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess \n",
    "\n",
    "## add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dfs(use_features, is_local=False, logger=None, debug=True):\n",
    "    # read dataframes     \n",
    "    with timer(\"read datasets\"):\n",
    "        if debug: \n",
    "            nrows=200000 \n",
    "        else: nrows=None\n",
    "            \n",
    "        sub = pd.read_csv(base_path + '/sample_submission.csv')\n",
    "        \n",
    "        if is_local:\n",
    "            org_train = pickle_load(\"../input/train.pkl\")\n",
    "            org_test = pickle_load(\"../input/test.pkl\")\n",
    "        else:\n",
    "            org_train = pd.read_csv(base_path + \"/train.csv\", nrows=nrows)\n",
    "            org_test = pd.read_csv(base_path + \"/test.csv\", nrows=nrows)\n",
    "            \n",
    "        org_train = memory_reducer(org_train, verbose=True)\n",
    "        org_test = org_test[org_test.installation_id.isin(sub.installation_id)]\n",
    "        org_test.sort_values(['installation_id', 'timestamp'], inplace=True)\n",
    "        org_test.reset_index(inplace=True)\n",
    "        org_test = memory_reducer(org_test, verbose=True)\n",
    "        \n",
    "        train_labels = pd.read_csv(base_path + \"/train_labels.csv\", nrows=nrows)\n",
    "        specs = pd.read_csv(base_path + \"/specs.csv\", nrows=nrows)\n",
    "\n",
    "    # basic preprocess\n",
    "    org_train[\"timestamp\"] = pd.to_datetime(org_train[\"timestamp\"])\n",
    "    org_test[\"timestamp\"] = pd.to_datetime(org_test[\"timestamp\"])\n",
    "    \n",
    "    with timer(\"merging features\"):\n",
    "        train_df = add_features(use_features, org_train, org_test, train_labels, specs, datatype=\"train\", is_local=is_local, logger=None)\n",
    "        train_df = train_df.reset_index(drop=True)\n",
    "        test_df = add_features(use_features, org_train, org_test, train_labels, specs, datatype=\"test\", is_local=is_local, logger=None)\n",
    "        test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "#     df = pd.concat([df, feat_df], axis=1)\n",
    "    print(\"preprocess done!!\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def feature_maker(feat_cls, is_overwrite, org_train, org_test, train_labels, params, logger, is_local):\n",
    "    \"\"\"featureの読み込み\n",
    "    \"\"\"\n",
    "    feat_ = feat_cls(train_labels, params, logger)\n",
    "    feat_name = feat_.name\n",
    "    datatype = feat_.datatype\n",
    "    feature_dir = os.path.join(os.path.dirname(\"__file__\"), \"../feature\")\n",
    "    feature_path = Path(feature_dir) / f\"{datatype}\" / f\"{feat_name}.pkl\"\n",
    "    \n",
    "    if os.path.exists(feature_path) and is_overwrite is False:\n",
    "        f_df = pickle_load(feature_path)\n",
    "    else:\n",
    "        f_df = feat_.feature_extract(org_train, org_test)\n",
    "    \n",
    "    return f_df\n",
    "\n",
    "\n",
    "def add_features(use_features, org_train, org_test, train_labels, specs, datatype, is_local=False, logger=None):\n",
    "    # 都度計算する\n",
    "    feat_params = {\n",
    "        \"datatype\": datatype,\n",
    "        \"debug\": True,\n",
    "        \"is_overwrite\": True,\n",
    "    }\n",
    "\n",
    "    # base feature\n",
    "    # kernel basics 2 にはバグがあるので、修正版の kernel basics 3 を使用する\n",
    "    # base_feat = KernelBasics2(train_labels, feat_params, logger)\n",
    "    base_feat = KernelBasics2(train_labels, feat_params, logger)    \n",
    "    feature_dir = os.path.join(os.path.dirname(\"__file__\"), \"../feature\")\n",
    "    feature_path = Path(feature_dir) / f\"{datatype}\" / f\"{base_feat.name}.pkl\"\n",
    "    \n",
    "    if os.path.exists(feature_path):\n",
    "        feat_df = pickle_load(feature_path)\n",
    "    else:\n",
    "        feat_df = base_feat.feature_extract(org_train, org_test)\n",
    "\n",
    "    # add event_counts\n",
    "    for name, feat_condition in use_features.items():\n",
    "        feat_cls = feat_condition[0]\n",
    "        is_overwrite = feat_condition[1]\n",
    "        \n",
    "        f_df = feature_maker(feat_cls, is_overwrite, org_train, org_test, train_labels, feat_params, logger, is_local)\n",
    "        feat_df = pd.merge(feat_df, f_df, how=\"left\", on =[\"installation_id\", \"game_session\"])\n",
    "        del f_df\n",
    "\n",
    "    return feat_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[read datasets] start\n",
      "event_id\n",
      "game_session\n",
      "timestamp\n",
      "event_data\n",
      "installation_id\n",
      "event_count\n",
      "event_code\n",
      "game_time\n",
      "title\n",
      "type\n",
      "world\n",
      "Mem. usage decreased to 778.73 Mb (18.2% reduction)\n",
      "index\n",
      "event_id\n",
      "game_session\n",
      "timestamp\n",
      "event_data\n",
      "installation_id\n",
      "event_count\n",
      "event_code\n",
      "game_time\n",
      "title\n",
      "type\n",
      "world\n",
      "Mem. usage decreased to 83.82 Mb (20.8% reduction)\n",
      "[read datasets] done in 97 s\n",
      "[merging features] start\n",
      "overwrite features : KernelBasics2\n",
      "[FE: KernelBasics2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  5.0min finished\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:71: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=9429562...\n",
      "calculate done!\n",
      "[FE: KernelBasics2] done in 377 s\n",
      "overwrite features : befTargetCntFeatures\n",
      "[FE: befTargetCntFeatures] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=727821...\n",
      "calculate done!\n",
      "[FE: befTargetCntFeatures] done in 95 s\n",
      "overwrite features : immediatelyBeforeFeatures\n",
      "[FE: immediatelyBeforeFeatures] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=16840814...\n",
      "calculate done!\n",
      "[FE: immediatelyBeforeFeatures] done in 235 s\n",
      "overwrite features : EventCount\n",
      "[FE: EventCount] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=4274932...\n",
      "calculate done!\n",
      "[FE: EventCount] done in 244 s\n",
      "overwrite features : EventCount2\n",
      "[FE: EventCount2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=33082141...\n",
      "calculate done!\n",
      "[FE: EventCount2] done in 489 s\n",
      "overwrite features : Worldcount\n",
      "[FE: Worldcount] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=5890975...\n",
      "calculate done!\n",
      "[FE: Worldcount] done in 496 s\n",
      "overwrite features : SessionTime2\n",
      "[FE: SessionTime2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 3607 out of 3614 | elapsed:  2.5min remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=3878080...\n",
      "calculate done!\n",
      "[FE: SessionTime2] done in 158 s\n",
      "overwrite features : EncodingTitles\n",
      "[FE: EncodingTitles] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=873681...\n",
      "calculate done!\n",
      "[FE: EncodingTitles] done in 132 s\n",
      "overwrite features : PrevAssessResult\n",
      "[FE: PrevAssessResult] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=1556161...\n",
      "calculate done!\n",
      "[FE: PrevAssessResult] done in 138 s\n",
      "overwrite features : PrevAssessAcc\n",
      "[FE: PrevAssessAcc] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 4242 out of 4242 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=1850185...\n",
      "calculate done!\n",
      "[FE: PrevAssessAcc] done in 186 s\n",
      "overwrite features : PrevAssessAccByTitle\n",
      "[FE: PrevAssessAccByTitle] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=4)]: Done 1272 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=4)]: Done 1740 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 2280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 2892 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done 3607 out of 3614 | elapsed:  2.5min remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=4685430...\n",
      "calculate done!\n",
      "[FE: PrevAssessAccByTitle] done in 175 s\n",
      "overwrite features : GameDurMiss\n",
      "[FE: GameDurMiss] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=4)]: Done 3614 out of 3614 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=3881720...\n",
      "calculate done!\n",
      "[FE: GameDurMiss] done in 405 s\n",
      "overwrite features : KernelBasics2\n",
      "[FE: KernelBasics2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=509659...\n",
      "calculate done!\n",
      "[FE: KernelBasics2] done in 96 s\n",
      "overwrite features : befTargetCntFeatures\n",
      "[FE: befTargetCntFeatures] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   23.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=46935...\n",
      "calculate done!\n",
      "[FE: befTargetCntFeatures] done in 24 s\n",
      "overwrite features : immediatelyBeforeFeatures\n",
      "[FE: immediatelyBeforeFeatures] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   41.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=2722700...\n",
      "calculate done!\n",
      "[FE: immediatelyBeforeFeatures] done in 43 s\n",
      "overwrite features : EventCount\n",
      "[FE: EventCount] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=207517...\n",
      "calculate done!\n",
      "[FE: EventCount] done in 50 s\n",
      "overwrite features : EventCount2\n",
      "[FE: EventCount2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=1506290...\n",
      "calculate done!\n",
      "[FE: EventCount2] done in 107 s\n",
      "overwrite features : Worldcount\n",
      "[FE: Worldcount] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=285396...\n",
      "calculate done!\n",
      "[FE: Worldcount] done in 112 s\n",
      "overwrite features : SessionTime2\n",
      "[FE: SessionTime2] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   41.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=199462...\n",
      "calculate done!\n",
      "[FE: SessionTime2] done in 42 s\n",
      "overwrite features : EncodingTitles\n",
      "[FE: EncodingTitles] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   28.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=46894...\n",
      "calculate done!\n",
      "[FE: EncodingTitles] done in 33 s\n",
      "overwrite features : PrevAssessResult\n",
      "[FE: PrevAssessResult] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   27.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=248341...\n",
      "calculate done!\n",
      "[FE: PrevAssessResult] done in 33 s\n",
      "overwrite features : PrevAssessAcc\n",
      "[FE: PrevAssessAcc] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=94157...\n",
      "calculate done!\n",
      "[FE: PrevAssessAcc] done in 39 s\n",
      "overwrite features : PrevAssessAccByTitle\n",
      "[FE: PrevAssessAccByTitle] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=4)]: Done 300 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done 552 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   37.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=240252...\n",
      "calculate done!\n",
      "[FE: PrevAssessAccByTitle] done in 41 s\n",
      "overwrite features : GameDurMiss\n",
      "[FE: GameDurMiss] start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing total_bytes=205264...\n",
      "calculate done!\n",
      "[FE: GameDurMiss] done in 95 s\n",
      "[merging features] done in 3847 s\n",
      "preprocess done!!\n"
     ]
    }
   ],
   "source": [
    "use_feature = {\n",
    "    \"befTargetCntFeatures\": [befTargetCntFeatures, True], # MUST!!!!\n",
    "    \"immediatelyBeforeFeatures\": [immediatelyBeforeFeatures, True],\n",
    "###    \"worldGameNumeriacalFeatures\": [worldGameNumeriacalFeatures, True],\n",
    "    \"EventCount\": [EventCount, True], # class, is_overwrite\n",
    "    \"EventCount2\": [EventCount2, True], # class, is_overwrite\n",
    "    \"Worldcount\": [Worldcount, True],\n",
    "    \"SessionTime\": [SessionTime2, True],\n",
    "####     \"AssessEventCount\": [AssessEventCount, False],\n",
    "    \"EncodingTitles\": [EncodingTitles, True],\n",
    "    \"PrevAssessResult\":[PrevAssessResult, True],\n",
    "    \"PrevAssessAcc\": [PrevAssessAcc, True],\n",
    "    \"PrevAssessAccByTitle\": [PrevAssessAccByTitle, True],\n",
    "    \"GameDurMiss\": [GameDurMiss, False],\n",
    "}\n",
    "\n",
    "is_local = False\n",
    "\n",
    "if is_local:\n",
    "    base_path = \"../input\" # at local\n",
    "    train_df, test_df = preprocess_dfs(use_feature, is_local=is_local, logger=None, debug=False)\n",
    "    \n",
    "else:\n",
    "    sub = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')\n",
    "    base_path = '/kaggle/input/data-science-bowl-2019' # at kaggle kernel\n",
    "#    if len(sub)==1000:\n",
    "    if False:\n",
    "        sub.to_csv('submission.csv', index=False)\n",
    "        exit(0)\n",
    "    else:\n",
    "        train_df, test_df = preprocess_dfs(use_feature, is_local=is_local, logger=None, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = [col.replace(',', '_') for col in train_df.columns]\n",
    "test_df.columns = [col.replace(',', '_') for col in test_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape: (17690, 640)\n",
      "['12 Monkeys', 'Air Show', 'All Star Sorting', 'Balancing Act', 'Bird Measurer (Assessment)', 'Bottle Filler (Activity)', 'Bubble Bath', 'Bug Measurer (Activity)', 'Cart Balancer (Assessment)', 'Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)', 'Chicken Balancer (Activity)', 'Chow Time', 'Costume Box', 'Crystal Caves - Level 1', 'Crystal Caves - Level 2', 'Crystal Caves - Level 3', 'Crystals Rule', 'Dino Dive', 'Dino Drink', 'Egg Dropper (Activity)', 'Fireworks (Activity)', 'Flower Waterer (Activity)', 'Happy Camel', 'Heavy_ Heavier_ Heaviest', 'Honey Cake', 'Leaf Leader', 'Lifting Heavy Things', 'Magma Peak - Level 1', 'Magma Peak - Level 2', 'Mushroom Sorter (Assessment)', 'Ordering Spheres', 'Pan Balance', \"Pirate's Tale\", 'Rulers', 'Sandcastle Builder (Activity)', 'Scrub-A-Dub', 'Slop Problem', 'Treasure Map', 'Tree Top City - Level 1', 'Tree Top City - Level 2', 'Tree Top City - Level 3', 'Watering Hole (Activity)', 'Welcome to Lost Lagoon!', 'accum_acc_gr_0', 'accum_acc_gr_1', 'accum_acc_gr_2', 'cum_accuracy', 'prev_acc_gr_0', 'prev_acc_gr_1', 'prev_acc_gr_2', 'prev_acc_gr_3', 'prev_cumnum_c', 'prev_cumnum_inc', 'prev_num_corrects', 'prev_num_incorrects', '1th_before_session_event_count_max', '1th_before_session_event_code_last', '1th_before_session_game_time_max', '1th_before_session_game_time_skew', '1th_before_session_game_time_kurt', '1th_before_session_title_LE', '1th_before_session_type_LE', '1th_before_session_world_LE', 'ev_cnt2000', 'ev_cnt2010', 'ev_cnt2020', 'ev_cnt2025', 'ev_cnt2030', 'ev_cnt2035', 'ev_cnt2040', 'ev_cnt2050', 'ev_cnt2060', 'ev_cnt2070', 'ev_cnt2075', 'ev_cnt2080', 'ev_cnt2081', 'ev_cnt2083', 'ev_cnt3020', 'ev_cnt3021', 'ev_cnt3120', 'ev_cnt3121', 'ev_cnt4010', 'ev_cnt4020', 'ev_cnt4021', 'ev_cnt4022', 'ev_cnt4025', 'ev_cnt4031', 'ev_cnt4035', 'ev_cnt4040', 'ev_cnt4045', 'ev_cnt4050', 'ev_cnt4080', 'ev_cnt4090', 'ev_cnt4095', 'ev_cnt4100', 'ev_cnt4110', 'ev_cnt4220', 'ev_cnt4230', 'ev_cnt4235', 'ev_cnt5000', 'ev_cnt5010', 'ev_cnt0086365d', 'ev_cnt00c73085', 'ev_cnt022b4259', 'ev_cnt02a42007', 'ev_cnt0330ab6a', 'ev_cnt0413e89d', 'ev_cnt04df9b66', 'ev_cnt05ad839b', 'ev_cnt06372577', 'ev_cnt070a5291', 'ev_cnt08fd73f3', 'ev_cnt08ff79ad', 'ev_cnt0a08139c', 'ev_cnt0d18d96c', 'ev_cnt0d1da71f', 'ev_cnt0db6d71d', 'ev_cnt1325467d', 'ev_cnt1340b8d7', 'ev_cnt1375ccb7', 'ev_cnt14de4c5d', 'ev_cnt155f62a4', 'ev_cnt1575e76c', 'ev_cnt15a43e5b', 'ev_cnt15ba1109', 'ev_cnt15eb4a7d', 'ev_cnt15f99afc', 'ev_cnt160654fd', 'ev_cnt16667cc5', 'ev_cnt16dffff1', 'ev_cnt17113b36', 'ev_cnt19967db1', 'ev_cnt1996c610', 'ev_cnt1af8be29', 'ev_cnt1bb5fbdb', 'ev_cnt1beb320a', 'ev_cnt1c178d24', 'ev_cnt1cc7cfca', 'ev_cnt1cf54632', 'ev_cnt1f19558b', 'ev_cnt222660ff', 'ev_cnt2230fab4', 'ev_cnt250513af', 'ev_cnt25fa8af4', 'ev_cnt262136f4', 'ev_cnt26a5a3dd', 'ev_cnt26fd2d99', 'ev_cnt27253bdc', 'ev_cnt28520915', 'ev_cnt28a4eb9a', 'ev_cnt28ed704e', 'ev_cnt28f975ea', 'ev_cnt29bdd9ba', 'ev_cnt29f54413', 'ev_cnt2a444e03', 'ev_cnt2a512369', 'ev_cnt2b058fe3', 'ev_cnt2b9272f4', 'ev_cnt2c4e6db0', 'ev_cnt2dc29e21', 'ev_cnt2dcad279', 'ev_cnt2fb91ec1', 'ev_cnt30614231', 'ev_cnt30df3273', 'ev_cnt31973d56', 'ev_cnt3323d7e9', 'ev_cnt33505eae', 'ev_cnt3393b68b', 'ev_cnt363c86c9', 'ev_cnt363d3849', 'ev_cnt36fa3ebe', 'ev_cnt37937459', 'ev_cnt37c53127', 'ev_cnt37db1c2f', 'ev_cnt37ee8496', 'ev_cnt38074c54', 'ev_cnt392e14df', 'ev_cnt3a4be871', 'ev_cnt3afb49e6', 'ev_cnt3afde5dd', 'ev_cnt3b2048ee', 'ev_cnt3babcb9b', 'ev_cnt3bb91ced', 'ev_cnt3bb91dda', 'ev_cnt3bf1cf26', 'ev_cnt3bfd1a65', 'ev_cnt3ccd3f02', 'ev_cnt3d0b9317', 'ev_cnt3d63345e', 'ev_cnt3d8c61b0', 'ev_cnt3dcdda7f', 'ev_cnt3ddc79c3', 'ev_cnt3dfd4aa4', 'ev_cnt3edf6747', 'ev_cnt3ee399c3', 'ev_cnt44cb4907', 'ev_cnt45d01abe', 'ev_cnt461eace6', 'ev_cnt46b50ba8', 'ev_cnt46cd75b4', 'ev_cnt47026d5f', 'ev_cnt47efca07', 'ev_cnt47f43a44', 'ev_cnt48349b14', 'ev_cnt4901243f', 'ev_cnt499edb7c', 'ev_cnt49ed92e9', 'ev_cnt4a09ace1', 'ev_cnt4a4c3d21', 'ev_cnt4b5efe37', 'ev_cnt4bb2f698', 'ev_cnt4c2ec19f', 'ev_cnt4d6737eb', 'ev_cnt4d911100', 'ev_cnt4e5fc6f5', 'ev_cnt4ef8cdd3', 'ev_cnt51102b85', 'ev_cnt51311d7a', 'ev_cnt5154fc30', 'ev_cnt5290eab1', 'ev_cnt532a2afb', 'ev_cnt5348fd84', 'ev_cnt53c6e11a', 'ev_cnt55115cbd', 'ev_cnt562cec5f', 'ev_cnt565a3990', 'ev_cnt56817e2b', 'ev_cnt56bcd38d', 'ev_cnt56cd3b43', 'ev_cnt5859dfb6', 'ev_cnt587b5989', 'ev_cnt58a0de5c', 'ev_cnt598f4598', 'ev_cnt5a848010', 'ev_cnt5b49460a', 'ev_cnt5be391b5', 'ev_cnt5c2f29ca', 'ev_cnt5c3d2b2f', 'ev_cnt5d042115', 'ev_cnt5de79a6a', 'ev_cnt5e109ec3', 'ev_cnt5e3ea25a', 'ev_cnt5e812b27', 'ev_cnt5f0eb72c', 'ev_cnt5f5b2617', 'ev_cnt6043a2b4', 'ev_cnt6077cc36', 'ev_cnt6088b756', 'ev_cnt63f13dd7', 'ev_cnt65a38bf7', 'ev_cnt65abac75', 'ev_cnt67439901', 'ev_cnt67aa2ada', 'ev_cnt69fdac0a', 'ev_cnt6aeafed4', 'ev_cnt6bf9e3e1', 'ev_cnt6c517a88', 'ev_cnt6c930e6e', 'ev_cnt6cf7d25c', 'ev_cnt6d90d394', 'ev_cnt6f445b57', 'ev_cnt6f4adc4b', 'ev_cnt6f4bd64e', 'ev_cnt6f8106d9', 'ev_cnt7040c096', 'ev_cnt709b1251', 'ev_cnt71e712d8', 'ev_cnt71fe8f75', 'ev_cnt731c0cbe', 'ev_cnt736f9581', 'ev_cnt7372e1a5', 'ev_cnt73757a5e', 'ev_cnt7423acbc', 'ev_cnt74e5f8a7', 'ev_cnt7525289a', 'ev_cnt756e5507', 'ev_cnt763fc34e', 'ev_cnt76babcde', 'ev_cnt77261ab5', 'ev_cnt77c76bc5', 'ev_cnt77ead60d', 'ev_cnt792530f8', 'ev_cnt795e4a37', 'ev_cnt7961e599', 'ev_cnt7ab78247', 'ev_cnt7ad3efc6', 'ev_cnt7cf1bc53', 'ev_cnt7d093bf9', 'ev_cnt7d5c30a2', 'ev_cnt7da34a02', 'ev_cnt7dfe6d8a', 'ev_cnt7ec0c298', 'ev_cnt7f0836bf', 'ev_cnt804ee27f', 'ev_cnt828e68f9', 'ev_cnt832735e1', 'ev_cnt83c6c409', 'ev_cnt84538528', 'ev_cnt84b0e0c8', 'ev_cnt857f21c0', 'ev_cnt85d1b0de', 'ev_cnt85de926c', 'ev_cnt86ba578b', 'ev_cnt86c924c4', 'ev_cnt87d743c1', 'ev_cnt884228c8', 'ev_cnt88d4a5be', 'ev_cnt895865f3', 'ev_cnt89aace00', 'ev_cnt8ac7cce4', 'ev_cnt8af75982', 'ev_cnt8b757ab8', 'ev_cnt8d748b58', 'ev_cnt8d7e386c', 'ev_cnt8d84fa81', 'ev_cnt8f094001', 'ev_cnt8fee50e2', 'ev_cnt907a054b', 'ev_cnt90d848e0', 'ev_cnt90ea0bac', 'ev_cnt90efca10', 'ev_cnt91561152', 'ev_cnt923afab1', 'ev_cnt92687c59', 'ev_cnt93b353f2', 'ev_cnt93edfe2e', 'ev_cnt9554a50b', 'ev_cnt99abe2bb', 'ev_cnt99ea62f3', 'ev_cnt9b01374f', 'ev_cnt9b23e8ee', 'ev_cnt9b4001e4', 'ev_cnt9c5ef70c', 'ev_cnt9ce586dd', 'ev_cnt9d29771f', 'ev_cnt9d4e7b25', 'ev_cnt9de5e594', 'ev_cnt9e34ea74', 'ev_cnt9e4c8c7b', 'ev_cnt9e6b7fb5', 'ev_cnt9ed8f6da', 'ev_cnt9ee1c98c', 'ev_cnta0faea5d', 'ev_cnta1192f43', 'ev_cnta16a373e', 'ev_cnta1bbe385', 'ev_cnta1e4395d', 'ev_cnta29c5338', 'ev_cnta2df0760', 'ev_cnta44b10dc', 'ev_cnta52b92d5', 'ev_cnta592d54e', 'ev_cnta5be6304', 'ev_cnta5e9da97', 'ev_cnta6d66e51', 'ev_cnta76029ee', 'ev_cnta7640a16', 'ev_cnta8876db3', 'ev_cnta8a78786', 'ev_cnta8efe47b', 'ev_cntab3136ba', 'ev_cntabc5811c', 'ev_cntac92046e', 'ev_cntacf5c23f', 'ev_cntad148f58', 'ev_cntad2fc29c', 'ev_cntb012cd7f', 'ev_cntb120f2ac', 'ev_cntb1d5101d', 'ev_cntb2dba42b', 'ev_cntb2e5b0f1', 'ev_cntb5053438', 'ev_cntb74258a0', 'ev_cntb7530680', 'ev_cntb7dc8128', 'ev_cntb80e5e84', 'ev_cntb88f38da', 'ev_cntbb3e370b', 'ev_cntbbfe0445', 'ev_cntbc8f2793', 'ev_cntbcceccc6', 'ev_cntbd612267', 'ev_cntbd701df8', 'ev_cntbdf49a58', 'ev_cntbeb0a7b9', 'ev_cntc0415e5c', 'ev_cntc189aaf2', 'ev_cntc1cac9a2', 'ev_cntc277e121', 'ev_cntc2baf0bd', 'ev_cntc51d8688', 'ev_cntc54cf6c5', 'ev_cntc58186bf', 'ev_cntc6971acf', 'ev_cntc7128948', 'ev_cntc74f40cd', 'ev_cntc7f7f0e1', 'ev_cntc7fe2a55', 'ev_cntc952eb01', 'ev_cntca11f653', 'ev_cntcb1178ad', 'ev_cntcb6010f8', 'ev_cntcc5087a3', 'ev_cntcdd22e43', 'ev_cntcf7638f3', 'ev_cntcf82af56', 'ev_cntcfbd47c8', 'ev_cntd02b7a8e', 'ev_cntd06f75b5', 'ev_cntd122731b', 'ev_cntd185d3ea', 'ev_cntd2278a3b', 'ev_cntd2659ab4', 'ev_cntd2e9262e', 'ev_cntd3268efa', 'ev_cntd3640339', 'ev_cntd38c2fd7', 'ev_cntd3f1e122', 'ev_cntd45ed6a1', 'ev_cntd51b1749', 'ev_cntd88ca108', 'ev_cntd88e8f25', 'ev_cntd9c005dd', 'ev_cntdaac11b0', 'ev_cntdb02c830', 'ev_cntdcaede90', 'ev_cntdcb55a27', 'ev_cntde26c3a6', 'ev_cntdf4940d3', 'ev_cntdf4fe8b6', 'ev_cnte04fb33d', 'ev_cnte080a381', 'ev_cnte37a2b78', 'ev_cnte3ff61fb', 'ev_cnte4f1efe6', 'ev_cnte5734469', 'ev_cnte57dd7af', 'ev_cnte5c9df6f', 'ev_cnte64e2cfd', 'ev_cnte694a35b', 'ev_cnte720d930', 'ev_cnte7561dd2', 'ev_cnte79f3763', 'ev_cnte7e44842', 'ev_cnte9c52111', 'ev_cntea296733', 'ev_cntea321fb1', 'ev_cnteb2c19cd', 'ev_cntec138c1c', 'ev_cntecaab346', 'ev_cntecc36b7f', 'ev_cntf28c589a', 'ev_cntf32856e4', 'ev_cntf3cd5473', 'ev_cntf50fc6c1', 'ev_cntf54238ee', 'ev_cntf56e0afc', 'ev_cntf5b8c21a', 'ev_cntf6947f54', 'ev_cntf71c4741', 'ev_cntf7e47413', 'ev_cntf806dc10', 'ev_cntf93fc684', 'ev_cntfbaf3456', 'ev_cntfcfdffb6', 'ev_cntfd20ea40', 'title_type_cnt_12 Monkeys_Clip', 'title_type_cnt_Air Show_Game', 'title_type_cnt_All Star Sorting_Game', 'title_type_cnt_Balancing Act_Clip', 'title_type_cnt_Bird Measurer (Assessment)_Assessment', 'title_type_cnt_Bottle Filler (Activity)_Activity', 'title_type_cnt_Bubble Bath_Game', 'title_type_cnt_Bug Measurer (Activity)_Activity', 'title_type_cnt_Cart Balancer (Assessment)_Assessment', 'title_type_cnt_Cauldron Filler (Assessment)_Assessment', 'title_type_cnt_Chest Sorter (Assessment)_Assessment', 'title_type_cnt_Chicken Balancer (Activity)_Activity', 'title_type_cnt_Chow Time_Game', 'title_type_cnt_Costume Box_Clip', 'title_type_cnt_Crystal Caves - Level 1_Clip', 'title_type_cnt_Crystal Caves - Level 2_Clip', 'title_type_cnt_Crystal Caves - Level 3_Clip', 'title_type_cnt_Crystals Rule_Game', 'title_type_cnt_Dino Dive_Game', 'title_type_cnt_Dino Drink_Game', 'title_type_cnt_Egg Dropper (Activity)_Activity', 'title_type_cnt_Fireworks (Activity)_Activity', 'title_type_cnt_Flower Waterer (Activity)_Activity', 'title_type_cnt_Happy Camel_Game', 'title_type_cnt_Heavy_ Heavier_ Heaviest_Clip', 'title_type_cnt_Honey Cake_Clip', 'title_type_cnt_Leaf Leader_Game', 'title_type_cnt_Lifting Heavy Things_Clip', 'title_type_cnt_Magma Peak - Level 1_Clip', 'title_type_cnt_Magma Peak - Level 2_Clip', 'title_type_cnt_Mushroom Sorter (Assessment)_Assessment', 'title_type_cnt_Ordering Spheres_Clip', 'title_type_cnt_Pan Balance_Game', \"title_type_cnt_Pirate's Tale_Clip\", 'title_type_cnt_Rulers_Clip', 'title_type_cnt_Sandcastle Builder (Activity)_Activity', 'title_type_cnt_Scrub-A-Dub_Game', 'title_type_cnt_Slop Problem_Clip', 'title_type_cnt_Treasure Map_Clip', 'title_type_cnt_Tree Top City - Level 1_Clip', 'title_type_cnt_Tree Top City - Level 2_Clip', 'title_type_cnt_Tree Top City - Level 3_Clip', 'title_type_cnt_Watering Hole (Activity)_Activity', 'title_type_cnt_Welcome to Lost Lagoon!_Clip', 'wrd_cnt_CRYSTALCAVES', 'wrd_cnt_MAGMAPEAK', 'wrd_cnt_NONE', 'wrd_cnt_TREETOPCITY', 'wrd_type_cnt_CRYSTALCAVES_Activity', 'wrd_type_cnt_CRYSTALCAVES_Assessment', 'wrd_type_cnt_CRYSTALCAVES_Clip', 'wrd_type_cnt_CRYSTALCAVES_Game', 'wrd_type_cnt_MAGMAPEAK_Activity', 'wrd_type_cnt_MAGMAPEAK_Assessment', 'wrd_type_cnt_MAGMAPEAK_Clip', 'wrd_type_cnt_MAGMAPEAK_Game', 'wrd_type_cnt_NONE_Clip', 'wrd_type_cnt_TREETOPCITY_Activity', 'wrd_type_cnt_TREETOPCITY_Assessment', 'wrd_type_cnt_TREETOPCITY_Clip', 'wrd_type_cnt_TREETOPCITY_Game', 'prev_gs_durationrmin', 'prev_ass_gs_duration', 'prev_ass_gs_duration_rmean', 'prev_ass_gs_duration_rstd', 'prev_ass_gs_duration_rmax', 'prev_ass_gs_duration_rmin', 'ass_session_interval_rmean', 'ass_session_interval_rstd', 'ass_session_interval_rmax', 'title_enc', 'accumassess_cnt_Bird Measurer (Assessment)', 'accumassess_cnt_Cart Balancer (Assessment)', 'accumassess_cnt_Cauldron Filler (Assessment)', 'accumassess_cnt_Chest Sorter (Assessment)', 'accumassess_cnt_Mushroom Sorter (Assessment)', 'assess_cnt_Bird Measurer (Assessment)', 'assess_cnt_Cart Balancer (Assessment)', 'assess_cnt_Cauldron Filler (Assessment)', 'assess_cnt_Chest Sorter (Assessment)', 'assess_cnt_Mushroom Sorter (Assessment)', 'as_acc_c_num', 'as_acc_inc_num', 'as_prev_acc', 'as_cum_acc', 'cum_acc_cum_Bird Measurer (Assessment)', 'cum_acc_cum_Cart Balancer (Assessment)', 'cum_acc_cum_Cauldron Filler (Assessment)', 'cum_acc_cum_Chest Sorter (Assessment)', 'cum_acc_cum_Mushroom Sorter (Assessment)', 'cum_num_correct_Bird Measurer (Assessment)', 'cum_num_correct_Cart Balancer (Assessment)', 'cum_num_correct_Cauldron Filler (Assessment)', 'cum_num_correct_Chest Sorter (Assessment)', 'cum_num_correct_Mushroom Sorter (Assessment)', 'cum_num_incorrect_Bird Measurer (Assessment)', 'cum_num_incorrect_Cart Balancer (Assessment)', 'cum_num_incorrect_Cauldron Filler (Assessment)', 'cum_num_incorrect_Chest Sorter (Assessment)', 'cum_num_incorrect_Mushroom Sorter (Assessment)', 'num_correct_Bird Measurer (Assessment)', 'num_correct_Cart Balancer (Assessment)', 'num_correct_Cauldron Filler (Assessment)', 'num_correct_Chest Sorter (Assessment)', 'num_correct_Mushroom Sorter (Assessment)', 'num_incorrect_Bird Measurer (Assessment)', 'num_incorrect_Cart Balancer (Assessment)', 'num_incorrect_Cauldron Filler (Assessment)', 'num_incorrect_Chest Sorter (Assessment)', 'num_incorrect_Mushroom Sorter (Assessment)', 'g_duration_max', 'g_duration_count', 'g_misses_min', 'g_misses_mean', 'g_misses_max', 'g_misses_std', 'mean_g_duration_min', 'mean_g_duration_mean', 'mean_g_duration_max', 'mean_g_duration_std', 'mean_g_duration_count', 'mean_g_misses_min', 'mean_g_misses_mean', 'mean_g_misses_max', 'mean_g_misses_std', 'cumnum']\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"suga_001_add_eventidcnt\"\n",
    "logger, log_path = log_output(exp_name)\n",
    "\n",
    "train_small_dataset = False\n",
    "is_debug = True\n",
    "\n",
    "# train_params = {\n",
    "#     'learning_rate': 0.01,\n",
    "#     'bagging_fraction': 0.90,\n",
    "#     'feature_fraction': 0.85,\n",
    "#     'max_depth': 5,\n",
    "#     'lambda_l1': 0.7,\n",
    "#     'lambda_l2': 0.7,\n",
    "#     'metric': 'multiclass',\n",
    "#     'objective': 'multiclass',\n",
    "#     'num_classes': 4,\n",
    "#     'random_state': 773,\n",
    "#     \"n_estimators\": 3000    \n",
    "\n",
    "# }\n",
    "\n",
    "train_params = {\n",
    "     'learning_rate': 0.01,\n",
    "     'boosting_type': 'gbdt',\n",
    "     'objective': 'regression',\n",
    "     'metric': 'rmse',\n",
    "    'num_leaves':  64,\n",
    "     'bagging_fraction': 0.9,\n",
    "     'bagging_freq': 1,\n",
    "     'feature_fraction': 0.7,\n",
    "     'max_depth': -1,\n",
    "     'lambda_l1': 0.2,\n",
    "     'lambda_l2': 0.4,    \n",
    "     'seed': 19930802,\n",
    "     'n_estimators': 100000,\n",
    "     'importance_type': 'gain',\n",
    "}\n",
    "\n",
    "bad_feats = [\n",
    "    'prev_gs_duration', 'session_intervalrmin', 'session_intervalrstd', 'session_intervalrmax', 'session_interval', 'accum_acc_gr_-99',\n",
    "    'session_intervalrmean', 'ass_session_interval', 'prev_gs_durationrmean', 'prev_gs_durationrmax',\n",
    "    'ev_cnt4070', 'prev_gs_durationrstd', 'mean_g_duration_meaan', 'ev_cnt3010', 'g_duration_std', 'ev_cnt4030', 'ev_cnt3110',\n",
    "    'g_duration_mean', 'meaan_g_duration_min', 'ass_session_interval_rmin', 'accum_acc_gr_3', 'g_duration_min', 'mean_g_duraation_std'\n",
    "]\n",
    "no_use_cols = [\n",
    "    \"accuracy\",\n",
    "    \"accuracy_group\",\n",
    "    \"game_session\",\n",
    "    \"installation_id\",\n",
    "    \"title\", \n",
    "    \"type\",\n",
    "    \"world\",\n",
    "    \"pred_y\",\n",
    "    \"bef_target_cnt\",\n",
    "] + list(set(train_df.columns) - set(test_df.columns)) + bad_feats\n",
    "\n",
    "\n",
    "train_cols = [c for c in list(train_df.columns) if c not in no_use_cols]\n",
    "    \n",
    "print(f\"train_df shape: {train_df.shape}\")\n",
    "print(train_cols)\n",
    "\n",
    "cat_cols = [\n",
    "            ]\n",
    "\n",
    "\n",
    "# logger.log(logging.DEBUG, f\"categorical cols: {cat_cols}\")\n",
    "\n",
    "target = \"accuracy_group\"\n",
    "\n",
    "model_conf = {\n",
    "    \"predict_type\": \"regressor\",\n",
    "    \"train_params\": train_params,\n",
    "    \"train_cols\": train_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"target\": target,\n",
    "    \"is_debug\": is_debug,\n",
    "}\n",
    "\n",
    "validation_param = {\n",
    "    \"model_name\": \"LGBM\",\n",
    "}\n",
    "\n",
    "exp_conf = {\n",
    "    \"train_small_dataset\": False,\n",
    "    \"use_feature\": {\n",
    "        \"sample\": True\n",
    "    },\n",
    "    \"train_params\": train_params,\n",
    "    \"exp_name\": exp_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 0.783603\tvalid_1's rmse: 1.05646\n",
      "[1000]\ttraining's rmse: 0.661252\tvalid_1's rmse: 1.05456\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's rmse: 0.716765\tvalid_1's rmse: 1.05355\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 0.785333\tvalid_1's rmse: 1.01082\n",
      "[1000]\ttraining's rmse: 0.663471\tvalid_1's rmse: 1.01207\n",
      "Early stopping, best iteration is:\n",
      "[621]\ttraining's rmse: 0.751318\tvalid_1's rmse: 1.009\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 0.785575\tvalid_1's rmse: 0.992599\n",
      "[1000]\ttraining's rmse: 0.663659\tvalid_1's rmse: 0.994672\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's rmse: 0.730107\tvalid_1's rmse: 0.991569\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 0.778198\tvalid_1's rmse: 1.07199\n",
      "[1000]\ttraining's rmse: 0.657514\tvalid_1's rmse: 1.06749\n",
      "[1500]\ttraining's rmse: 0.569355\tvalid_1's rmse: 1.06674\n",
      "Early stopping, best iteration is:\n",
      "[1326]\ttraining's rmse: 0.597862\tvalid_1's rmse: 1.06611\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 0.773742\tvalid_1's rmse: 1.05563\n",
      "[1000]\ttraining's rmse: 0.652416\tvalid_1's rmse: 1.05784\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's rmse: 0.735078\tvalid_1's rmse: 1.0544\n"
     ]
    }
   ],
   "source": [
    "# v = Validation(validation_param, exp_conf, train_df, test_df, logger)\n",
    "v = Validation2(validation_param, exp_conf, train_df, test_df, logger)\n",
    "clf, oof, prediction, feature_importance, labels = v.do_valid_kfold(model_conf, trn_mode='simple',val_mode='last_truncated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = prediction.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-3a0132078fe8>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"qwk\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-8-3a0132078fe8> (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-3a0132078fe8>\", line 3:\u001b[0m\n",
      "\u001b[1mdef qwk(y_true, y_pred, max_rat= 3):\n",
      "\u001b[1m    y_true_ = np.asarray(y_true, dtype=int)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-8-3a0132078fe8>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"qwk\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-3a0132078fe8>\", line 10:\u001b[0m\n",
      "\u001b[1mdef qwk(y_true, y_pred, max_rat= 3):\n",
      "    <source elided>\n",
      "    numerator = 0\n",
      "\u001b[1m    for k in range(y_true_.shape[0]):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "/opt/conda/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"qwk\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-3a0132078fe8>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef qwk(y_true, y_pred, max_rat= 3):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/opt/conda/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-8-3a0132078fe8>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef qwk(y_true, y_pred, max_rat= 3):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5756972114699381"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optR = OptimizedRounder()\n",
    "optR = OptimizedRounder_v2()\n",
    "#optR.fit(oof, train_df[target])\n",
    "optR.fit(oof[oof != 0], labels[oof != 0])\n",
    "coefficients = optR.coefficients()\n",
    "\n",
    "opt_preds = optR.predict(oof[oof != 0], coefficients)\n",
    "qwk(labels[oof != 0], opt_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d8e089748>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(oof[oof != 0]).hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d38a915f8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(prediction).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93194915, 1.61449192, 2.23388149])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients\n",
    "\n",
    "prediction = optR.predict(prediction, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>title_enc</td>\n",
       "      <td>90306.082335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>as_cum_acc</td>\n",
       "      <td>80120.110299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>title_type_cnt_Crystal Caves - Level 3_Clip</td>\n",
       "      <td>34134.226344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>as_prev_acc</td>\n",
       "      <td>23937.229863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>cum_accuracy</td>\n",
       "      <td>23275.146126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>accum_acc_gr_0</td>\n",
       "      <td>15938.241068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1th_before_session_world_LE</td>\n",
       "      <td>14040.329359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>assess_cnt_Cart Balancer (Assessment)</td>\n",
       "      <td>8292.671972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>as_acc_inc_num</td>\n",
       "      <td>8250.427574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>as_acc_c_num</td>\n",
       "      <td>8118.839789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>mean_g_misses_mean</td>\n",
       "      <td>7694.565387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>cum_acc_cum_Chest Sorter (Assessment)</td>\n",
       "      <td>7129.661145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ev_cnt27253bdc</td>\n",
       "      <td>6578.995639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>mean_g_duration_std</td>\n",
       "      <td>6199.526674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1th_before_session_game_time_skew</td>\n",
       "      <td>5746.292231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>g_misses_mean</td>\n",
       "      <td>5650.487183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ev_cnt2000</td>\n",
       "      <td>5587.732305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>cum_acc_cum_Mushroom Sorter (Assessment)</td>\n",
       "      <td>5411.154371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ev_cnt7372e1a5</td>\n",
       "      <td>5383.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1th_before_session_game_time_kurt</td>\n",
       "      <td>5272.486977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ev_cnt3020</td>\n",
       "      <td>5005.419337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cum_acc_cum_Cart Balancer (Assessment)</td>\n",
       "      <td>4764.008899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>prev_ass_gs_duration_rmin</td>\n",
       "      <td>4473.965795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1th_before_session_title_LE</td>\n",
       "      <td>4457.664795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>g_duration_max</td>\n",
       "      <td>4351.748433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>prev_ass_gs_duration</td>\n",
       "      <td>4299.295634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>g_misses_std</td>\n",
       "      <td>4066.087051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>prev_ass_gs_duration_rstd</td>\n",
       "      <td>4055.831798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>mean_g_duration_min</td>\n",
       "      <td>4039.998693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>prev_ass_gs_duration_rmean</td>\n",
       "      <td>4028.716233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>mean_g_misses_std</td>\n",
       "      <td>4016.251390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>mean_g_duration_mean</td>\n",
       "      <td>3804.412782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1th_before_session_event_code_last</td>\n",
       "      <td>3778.149870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ass_session_interval_rstd</td>\n",
       "      <td>3682.694424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ev_cnt4020</td>\n",
       "      <td>3619.318152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>mean_g_duration_max</td>\n",
       "      <td>3554.899724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ass_session_interval_rmean</td>\n",
       "      <td>3548.855653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1th_before_session_event_count_max</td>\n",
       "      <td>3533.990090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>prev_ass_gs_duration_rmax</td>\n",
       "      <td>3359.008252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1th_before_session_game_time_max</td>\n",
       "      <td>3269.770849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ev_cnt4035</td>\n",
       "      <td>3168.586470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>mean_g_duration_count</td>\n",
       "      <td>2831.640547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ev_cnt1325467d</td>\n",
       "      <td>2694.206409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ev_cnt0db6d71d</td>\n",
       "      <td>2676.513495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ass_session_interval_rmax</td>\n",
       "      <td>2673.845100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>wrd_type_cnt_TREETOPCITY_Clip</td>\n",
       "      <td>2669.775914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ev_cnt3ee399c3</td>\n",
       "      <td>2507.768657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>g_duration_count</td>\n",
       "      <td>2448.313485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>mean_g_misses_max</td>\n",
       "      <td>2259.226794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>cum_acc_cum_Bird Measurer (Assessment)</td>\n",
       "      <td>2256.327029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         feature    importance\n",
       "531                                    title_enc  90306.082335\n",
       "62                                    as_cum_acc  80120.110299\n",
       "548  title_type_cnt_Crystal Caves - Level 3_Clip  34134.226344\n",
       "63                                   as_prev_acc  23937.229863\n",
       "77                                  cum_accuracy  23275.146126\n",
       "52                                accum_acc_gr_0  15938.241068\n",
       "8                    1th_before_session_world_LE  14040.329359\n",
       "68         assess_cnt_Cart Balancer (Assessment)   8292.671972\n",
       "61                                as_acc_inc_num   8250.427574\n",
       "60                                  as_acc_c_num   8118.839789\n",
       "504                           mean_g_misses_mean   7694.565387\n",
       "75         cum_acc_cum_Chest Sorter (Assessment)   7129.661145\n",
       "149                               ev_cnt27253bdc   6578.995639\n",
       "502                          mean_g_duration_std   6199.526674\n",
       "5              1th_before_session_game_time_skew   5746.292231\n",
       "495                                g_misses_mean   5650.487183\n",
       "128                                   ev_cnt2000   5587.732305\n",
       "76      cum_acc_cum_Mushroom Sorter (Assessment)   5411.154371\n",
       "296                               ev_cnt7372e1a5   5383.900600\n",
       "3              1th_before_session_game_time_kurt   5272.486977\n",
       "164                                   ev_cnt3020   5005.419337\n",
       "73        cum_acc_cum_Cart Balancer (Assessment)   4764.008899\n",
       "524                    prev_ass_gs_duration_rmin   4473.965795\n",
       "6                    1th_before_session_title_LE   4457.664795\n",
       "493                               g_duration_max   4351.748433\n",
       "521                         prev_ass_gs_duration   4299.295634\n",
       "497                                 g_misses_std   4066.087051\n",
       "525                    prev_ass_gs_duration_rstd   4055.831798\n",
       "501                          mean_g_duration_min   4039.998693\n",
       "523                   prev_ass_gs_duration_rmean   4028.716233\n",
       "506                            mean_g_misses_std   4016.251390\n",
       "500                         mean_g_duration_mean   3804.412782\n",
       "1             1th_before_session_event_code_last   3778.149870\n",
       "66                     ass_session_interval_rstd   3682.694424\n",
       "202                                   ev_cnt4020   3619.318152\n",
       "499                          mean_g_duration_max   3554.899724\n",
       "65                    ass_session_interval_rmean   3548.855653\n",
       "2             1th_before_session_event_count_max   3533.990090\n",
       "522                    prev_ass_gs_duration_rmax   3359.008252\n",
       "4               1th_before_session_game_time_max   3269.770849\n",
       "207                                   ev_cnt4035   3168.586470\n",
       "498                        mean_g_duration_count   2831.640547\n",
       "105                               ev_cnt1325467d   2694.206409\n",
       "104                               ev_cnt0db6d71d   2676.513495\n",
       "64                     ass_session_interval_rmax   2673.845100\n",
       "591                wrd_type_cnt_TREETOPCITY_Clip   2669.775914\n",
       "200                               ev_cnt3ee399c3   2507.768657\n",
       "492                             g_duration_count   2448.313485\n",
       "503                            mean_g_misses_max   2259.226794\n",
       "72        cum_acc_cum_Bird Measurer (Assessment)   2256.327029"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.groupby(\"feature\")[\"importance\"].mean().reset_index().sort_values(\"importance\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_df =  pd.read_csv(base_path + \"/sample_submission.csv\")\n",
    "# prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.456\n",
       "2    0.280\n",
       "1    0.138\n",
       "0    0.126\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[\"accuracy_group\"] = prediction\n",
    "# .argmax(axis = 1)\n",
    "sub_df[\"accuracy_group\"].value_counts(normalize=True)\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
